<!DOCTYPE html>
<html id="blog">
<head>
  <meta charset="utf-8">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <link rel="shortcut icon" type="image/png" href="/images/favicon.png">
  <link rel="stylesheet" type="text/css" href="/css/base_fonts.css">
  <link rel="stylesheet" type="text/css" href="/css/jquery-ui.min.css">
  <link rel='stylesheet' type='text/css' href='https://maxcdn.bootstrapcdn.com/bootstrap/3.3.7/css/bootstrap.min.css'>
  <!-- <link rel="stylesheet" type="text/css" href="/css/case_study_styles.css"> -->
  <link rel="stylesheet" type="text/css" href="/css/blog.css">
  <link rel="stylesheet" type="text/css" href="/css/styles.css">
  <!-- <link rel="stylesheet" type="text/css" href="/css/sweetalert.css"> -->
  <link rel="stylesheet" type="text/css" href="/css/callouts.css">

  <link rel="stylesheet" type="text/css" href="/css/custom-jekyll/tags.css">
  
  <link rel="stylesheet" type="text/css" href="/css/gridpage.css">
  <link rel="stylesheet" type="text/css" href="/css/blog.css">

  
  <meta name="description" content="" />
  

  <script src="/js/jquery-2.2.0.min.js"></script>
  <script src="/js/jquery-ui.min.js"></script>
  <script src="https://maxcdn.bootstrapcdn.com/bootstrap/3.3.7/js/bootstrap.min.js" integrity="sha384-Tc5IQib027qvyjSMfHjOMaLkfuWVxZxUPnCJA7l2mCWNIpG9mGCD8wGNIcPD7Txa" crossorigin="anonymous"></script>
  <script src="/js/script.js"></script>
  <script src="/js/sweetalert.min.js"></script>
  <script src="/js/custom-jekyll/tags.js"></script>
  <script defer src="https://use.fontawesome.com/releases/v5.0.6/js/all.js"></script>

  <link type="application/atom+xml" rel="alternate" href="http://0.0.0.0:4000/feed.xml" title="Kubernetes" />

  <!-- Begin Jekyll SEO tag v2.4.0 -->
<title>Kubernetes | Production-Grade Container Orchestration</title>
<meta name="generator" content="Jekyll v3.6.0" />
<meta property="og:title" content="Kubernetes" />
<meta property="og:locale" content="en_US" />
<meta name="description" content="Production-Grade Container Orchestration" />
<meta property="og:description" content="Production-Grade Container Orchestration" />
<link rel="canonical" href="http://0.0.0.0:4000/blog/page17/" />
<meta property="og:url" content="http://0.0.0.0:4000/blog/page17/" />
<meta property="og:site_name" content="Kubernetes" />
<link rel="prev" href="http://0.0.0.0:4000/blog/page16/" />
<link rel="next" href="http://0.0.0.0:4000/blog/page18/" />
<meta name="twitter:card" content="summary" />
<meta name="twitter:site" content="@kubernetesio" />
<script type="application/ld+json">
{"description":"Production-Grade Container Orchestration","@type":"WebPage","url":"http://0.0.0.0:4000/blog/page17/","publisher":{"@type":"Organization","logo":{"@type":"ImageObject","url":"http://0.0.0.0:4000/images/favicon.png"}},"headline":"Kubernetes","@context":"http://schema.org"}</script>
<!-- End Jekyll SEO tag -->

</head>



<body>
  <div id="cellophane" onclick="kub.toggleMenu()"></div>
  <header>
    <nav  class="nav-buttons" data-auto-burger="primary">
      <ul class="global-nav">
        <li><a href="/docs/home/">Documentation</a></li>
        <li><a href="/blog">Blog</a></li>
        <li><a href="/partners/">Partners</a></li>
        <li><a href="/community/">Community</a></li>
        <li><a href="/case-studies/">Case Studies</a></li>
        <li>
          <a href="#">
            v1.10 <span class="ui-icon ui-icon-carat-1-s"></span>
          </a>
          <ul>
            
            
            <li><a href="https://kubernetes.io/blog/page17/">v1.10</a></li>
            
            
            
            <li><a href="https://v1-9.docs.kubernetes.io/blog/page17/">v1.9</a></li>
            
            
            
            <li><a href="https://v1-8.docs.kubernetes.io/blog/page17/">v1.8</a></li>
            
            
            
            <li><a href="https://v1-7.docs.kubernetes.io/blog/page17/">v1.7</a></li>
            
            
            
            <li><a href="https://v1-6.docs.kubernetes.io/blog/page17/">v1.6</a></li>
            
            
          </ul>
        </li>
      </li>
    </ul>
    <a href="/docs/home" class="button" id="viewDocs" data-auto-burger-exclude>View Documentation</a>
    <a href="/docs/tutorials/kubernetes-basics/" class="button" id="tryKubernetes" data-auto-burger-exclude>Try Kubernetes</a>
    <button id="hamburger" onclick="kub.toggleMenu()" data-auto-burger-exclude><div></div></button>
  </nav>
</div>
</header>

<div class="container-fluid">
  <div id="blog-hero" class="light-text">
      <a class= 'logo' href='http://kubernetes.io/'></a>
  <div class='blog-title'>
      <h1> Kubernetes Blog </h1>
    </div>

  <div class="clear" style="clear: both"></div>
  </div>


  <div class="row blog-content" >
   <div class="col-xs-10 col-sm-9 col-lg-9 text">

       <h4 class="date-header"> </h4>
      <h3 class="post-title entry-title">   </h3>
        
    <h1><a href="/blog/2016/07/stateful-applications-in-containers-kubernetes"> Stateful Applications in Containers!? Kubernetes 1.3 Says “Yes!” </a></h1>
    <p class="author">
      <h2><span class="date-header">July 13 2016</span></h2>
    </p>
    <div class="content">
      <p><em>Editor’s note: today’s guest post is from Mark Balch, VP of Products at Diamanti, who’ll share more about the contributions they’ve made to Kubernetes.</em></p>

<p>Congratulations to the Kubernetes community on another <a href="http://blog.kubernetes.io/2016/07/kubernetes-1.3-bridging-cloud-native-and-enterprise-workloads.html">value-packed release</a>. A focus on stateful applications and federated clusters are two reasons why I’m so excited about 1.3. Kubernetes support for stateful apps such as Cassandra, Kafka, and MongoDB is critical. Important services rely on databases, key value stores, message queues, and more. Additionally, relying on one data center or container cluster simply won’t work as apps grow to serve millions of users around the world. Cluster federation allows users to deploy apps across multiple clusters and data centers for scale and resiliency.</p>

<p>You may have <a href="https://www.diamanti.com/blog/the-next-great-application-platform/">heard me say before</a> that containers are the next great application platform. Diamanti is accelerating container adoption for stateful apps in production - where performance and ease of deployment really matter. </p>

<p><strong>Apps Need More Than Cattle</strong></p>

<p>Beyond stateless containers like web servers (so-called “cattle” because they are interchangeable), users are increasingly deploying stateful workloads with containers to benefit from “build once, run anywhere” and to improve bare metal efficiency/utilization. These “pets” (so-called because each requires special handling) bring new requirements including longer life cycle, configuration dependencies, stateful failover, and performance sensitivity. Container orchestration must address these needs to successfully deploy and scale apps.</p>

<p>Enter <a href="http://kubernetes.io/docs/user-guide/petset/">Pet Set</a>, a new object in Kubernetes 1.3 for improved stateful application support. Pet Set sequences through the startup phase of each database replica (for example), ensuring orderly master/slave configuration. Pet Set also simplifies service discovery by leveraging ubiquitous DNS SRV records, a well-recognized and long-understood mechanism.</p>

<p>Diamanti’s <a href="https://github.com/kubernetes/kubernetes/pull/13840">FlexVolume contribution</a> to Kubernetes enables stateful workloads by providing persistent volumes with low-latency storage and guaranteed performance, including enforced quality-of-service from container to media.</p>

<p><strong>A Federalist</strong></p>

<p>Users who are planning for application availability must contend with issues of failover and scale across geography. Cross-cluster federated services allows containerized apps to easily deploy across multiple clusters. Federated services tackles challenges such as managing multiple container clusters and coordinating service deployment and discovery across federated clusters.</p>

<p>Like a strictly centralized model, federation provides a common app deployment interface. With each cluster retaining autonomy, however, federation adds flexibility to manage clusters locally during network outages and other events. Cross-cluster federated services also applies consistent service naming and adoption across container clusters, simplifying DNS resolution.</p>

<p>It’s easy to imagine powerful multi-cluster use cases with cross-cluster federated services in future releases. An example is scheduling containers based on governance, security, and performance requirements. Diamanti’s scheduler extension was developed with this concept in mind. Our <a href="https://github.com/kubernetes/kubernetes/pull/13580">first implementation</a> makes the Kubernetes scheduler aware of network and storage resources local to each cluster node. Similar concepts can be applied in the future to broader placement controls with cross-cluster federated services. </p>

<p><strong>Get Involved</strong></p>

<p>With interest growing in stateful apps, work has already started to further enhance Kubernetes storage. The Storage Special Interest Group is discussing proposals to support local storage resources. Diamanti is looking forward to extend FlexVolume to include richer APIs that enable local storage and storage services including data protection, replication, and reduction. We’re also working on proposals for improved app placement, migration, and failover across container clusters through Kubernetes cross-cluster federated services.</p>

<p>Join the conversation and contribute! Here are some places to get started:</p>

<ul>
  <li>Product Management <a href="https://groups.google.com/forum/#!forum/kubernetes-pm">group</a></li>
  <li>Kubernetes <a href="https://groups.google.com/forum/#!forum/kubernetes-sig-storage">Storage SIG</a> </li>
  <li>Kubernetes <a href="https://groups.google.com/forum/#!forum/kubernetes-sig-federation">Cluster Federation SIG</a></li>
</ul>

<p><em>– Mark Balch, VP Products, <a href="https://diamanti.com/">Diamanti</a>. Twitter <a href="https://twitter.com/markbalch">@markbalch</a></em></p>

    </div>
  
    <h1><a href="/blog/2016/07/Thousand-Instances-Of-Cassandra-Using-Kubernetes-Pet-Set"> Thousand Instances of Cassandra using Kubernetes Pet Set </a></h1>
    <p class="author">
      <h2><span class="date-header">July 13 2016</span></h2>
    </p>
    <div class="content">
      <p><em>Editor’s note: this post is part of a <a href="http://blog.kubernetes.io/2016/07/five-days-of-kubernetes-1.3.html">series of in-depth articles</a> on what’s new in Kubernetes 1.3</em></p>

<h2 id="running-the-greek-pet-monster-races">Running The Greek Pet Monster Races</h2>

<p>For the <a href="http://blog.kubernetes.io/2016/07/kubernetes-1.3-bridging-cloud-native-and-enterprise-workloads.html">Kubernetes 1.3 launch</a>, we wanted to put the new Pet Set through its paces. By testing a thousand instances of <a href="https://cassandra.apache.org/">Cassandra</a>, we could make sure that Kubernetes 1.3 was production ready. Read on for how we adapted Cassandra to Kubernetes, and had our largest deployment ever.</p>

<p>It’s fairly straightforward to use containers with basic stateful applications today. Using a persistent volume, you can mount a disk in a pod, and ensure that your data lasts beyond the life of your pod. However, with deployments of distributed stateful applications, things can become more tricky. With Kubernetes 1.3, the new <a href="http://kubernetes.io/docs/user-guide/petset/">Pet Set</a> component makes everything much easier. To test this new feature out at scale, we decided to host the Greek Pet Monster Races! We raced Centaurs and other Ancient Greek Monsters over hundreds of thousands of races across multiple availability zones.</p>

<p><a href="https://upload.wikimedia.org/wikipedia/commons/thumb/4/42/Cassandra1.jpeg/283px-Cassandra1.jpeg"><img src="https://upload.wikimedia.org/wikipedia/commons/thumb/4/42/Cassandra1.jpeg/283px-Cassandra1.jpeg" alt="File:Cassandra1.jpeg" /></a><br /> As many of you know Kubernetes is from the Ancient Greek: κυβερνήτης. This means helmsman, pilot, steersman, or ship master. So in order to keep track of race results, we needed a data store, and we choose Cassandra. Κασσάνδρα, Cassandra who was the daughter of King of Priam and Queen Hecuba of Troy. With multiple references to the ancient Greek language, we thought it would be appropriate to race ancient Greek monsters.</p>

<p>From there the story kinda goes sideways because Cassandra was actually the Pets as well. Read on and we will explain.</p>

<p>One of the new exciting features in Kubernetes 1.3 is Pet Set. In order to organize the deployment of containers inside of Kubernetes, different deployment mechanisms are available. Examples of these components include Resource Controllers and Daemon Set. Pet Sets is a new feature that delivers the capability to deploy containers, as Pets, inside of Kubernetes. Pet Sets provide a guarantee of identity for various aspects of the pet / pod deployment: DNS name, consistent storage, and ordered pod indexing. Previously, using components like Deployments and Replication Controllers, would only deploy an application with a weak uncoupled identity. A weak identity is great for managing applications such as microservices, where service discovery is important, the application is stateless, and the naming of individual pods does not matter. Many software applications do require strong identity, including many different types of distributed stateful systems. Cassandra is a great example of a distributed application that requires consistent network identity, and stable storage.</p>

<p>Pet Sets provides the following capabilities:</p>

<ul>
  <li>A stable hostname, available to others in DNS. Number is based off of the Pet Set name and starts at zero. For example cassandra-0.</li>
  <li>An ordinal index of Pets. 0, 1, 2, 3, etc.</li>
  <li>Stable storage linked to the ordinal and hostname of the Pet.</li>
  <li>Peer discovery is available via DNS. With Cassandra the names of the peers are known before the Pets are created.</li>
  <li>Startup and Teardown ordering. Which numbered Pet is going to be created next is known, and which Pet will be destroyed upon reducing the Pet Set size. This feature is useful for such admin tasks as draining data from a Pet, when reducing the size of a cluster.</li>
</ul>

<p>If your application has one or more of these requirements, then it may be a candidate for Pet Set.<br /> A relevant analogy is that a Pet Set is composed of Pet dogs. If you have a white, brown or black dog and the brown dog runs away, you can replace it with another brown dog no one would notice. If over time you can keep replacing your dogs with only white dogs then someone would notice. Pet Set allows your application to maintain the unique identity or hair color of your Pets.</p>

<p>Example workloads for Pet Set:</p>

<ul>
  <li>Clustered software like Cassandra, Zookeeper, etcd, or Elastic require stable membership.</li>
  <li>Databases like MySQL or PostgreSQL that require a single instance attached to a persistent volume at any time.</li>
</ul>

<p>Only use Pet Set if your application requires some or all of these properties. Managing pods as stateless replicas is vastly easier.</p>

<p>So back to our races!</p>

<p>As we have mentioned, Cassandra was a perfect candidate to deploy via a Pet Set. A Pet Set is much like a <a href="http://kubernetes.io/docs/user-guide/replication-controller/">Replica Controller</a> with a few new bells and whistles. Here’s an example YAML manifest:</p>

<h1 id="headless-service-to-provide-dns-lookup">Headless service to provide DNS lookup</h1>
<div class="highlighter-rouge">
  <div class="highlight">
    <div class="highlight highlighter-rouge"><div class="highlight"><pre class="highlight"><code>apiVersion: v1

kind: Service

metadata:

  labels:

    app: cassandra

  name: cassandra

spec:

  clusterIP: None

  ports:

    - port: 9042

  selector:

    app: cassandra-data

----

# new API name

apiVersion: "apps/v1alpha1"

kind: PetSet

metadata:

  name: cassandra

spec:

  serviceName: cassandra

  # replicas are the same as used by Replication Controllers

  # except pets are deployed in order 0, 1, 2, 3, etc

  replicas: 5

  template:

    metadata:

      annotations:

        pod.alpha.kubernetes.io/initialized: "true"

      labels:

        app: cassandra-data

    spec:

      # just as other component in Kubernetes one

      # or more containers are deployed

      containers:

      - name: cassandra

        image: "cassandra-debian:v1.1"

        imagePullPolicy: Always

        ports:

        - containerPort: 7000

          name: intra-node

        - containerPort: 7199

          name: jmx

        - containerPort: 9042

          name: cql

        resources:

          limits:

            cpu: "4"

            memory: 11Gi

          requests:

           cpu: "4"

           memory: 11Gi

        securityContext:

          privileged: true

        env:

          - name: MAX\_HEAP\_SIZE

            value: 8192M

          - name: HEAP\_NEWSIZE

            value: 2048M

          # this is relying on guaranteed network identity of Pet Sets, we

          # will know the name of the Pets / Pod before they are created

          - name: CASSANDRA\_SEEDS

            value: "cassandra-0.cassandra.default.svc.cluster.local,cassandra-1.cassandra.default.svc.cluster.local"

          - name: CASSANDRA\_CLUSTER\_NAME

            value: "OneKDemo"

          - name: CASSANDRA\_DC

            value: "DC1-Data"

          - name: CASSANDRA\_RACK

            value: "OneKDemo-Rack1-Data"

          - name: CASSANDRA\_AUTO\_BOOTSTRAP

            value: "false"

          # this variable is used by the read-probe looking

          # for the IP Address in a `nodetool status` command

          - name: POD\_IP

            valueFrom:

              fieldRef:

                fieldPath: status.podIP

        readinessProbe:

          exec:

            command:

            - /bin/bash

            - -c

            - /ready-probe.sh

          initialDelaySeconds: 15

          timeoutSeconds: 5

        # These volume mounts are persistent. They are like inline claims,

        # but not exactly because the names need to match exactly one of

        # the pet volumes.

        volumeMounts:

        - name: cassandra-data

          mountPath: /cassandra\_data

  # These are converted to volume claims by the controller

  # and mounted at the paths mentioned above.  Storage can be automatically

  # created for the Pets depending on the cloud environment.

  volumeClaimTemplates:

  - metadata:

      name: cassandra-data

      annotations:

        volume.alpha.kubernetes.io/storage-class: anything

    spec:

      accessModes: ["ReadWriteOnce"]

      resources:

        requests:
          storage: 380Gi
</code></pre></div>    </div>
  </div>
</div>

<p>You may notice that these containers are on the rather large size, and it is not unusual to run Cassandra in production with 8 CPU and 16GB of ram. There are two key new features that you will notice above; dynamic volume provisioning, and of course Pet Set. The above manifest will create 5 Cassandra Pets / Pods starting with the number 0: cassandra-data-0, cassandra-data-1, etc.</p>

<p>In order to generate data for the races, we used another Kubernetes feature called Jobs. Simple python code was written to generate the random speed of the monster for every second of the race. Then that data, position information, winners, other data points, and metrics were stored in Cassandra. To visualize the data, we used JHipster to generate a AngularJS UI with Java services, and then used D3 for graphing.</p>

<p>An example of one of the Jobs:</p>

<div class="highlighter-rouge">
  <div class="highlight">
    <div class="highlight highlighter-rouge"><div class="highlight"><pre class="highlight"><code>apiVersion: batch/v1

kind: Job

metadata:

  name: pet-race-giants

  labels:

    name: pet-races

spec:

  parallelism: 2

  completions: 4

  template:

    metadata:

      name: pet-race-giants

      labels:

        name: pet-races

    spec:

      containers:

      - name: pet-race-giants

        image: py3numpy-job:v1.0

        command: ["pet-race-job", --length=100", "--pet=Giants", "--scale=3"]

        resources:

          limits:

            cpu: "2"

          requests:

            cpu: "2"

      restartPolicy: Never
</code></pre></div>    </div>
  </div>
</div>

<p><a href="https://upload.wikimedia.org/wikipedia/commons/0/0e/Polyphemus.gif"><img src="https://upload.wikimedia.org/wikipedia/commons/0/0e/Polyphemus.gif" alt="File:Polyphemus.gif" /></a>Since we are talking about Monsters, we had to go big. We deployed 1,009 minion nodes to <a href="https://cloud.google.com/compute/">Google Compute Engine</a> (GCE), spread across 4 zones, running a custom version of the Kubernetes 1.3 beta. We ran this demo on beta code since the demo was being set up before the 1.3 release date. For the minion nodes, GCE virtual machine n1-standard-8 machine size was chosen, which is vm with 8 virtual CPUs and 30GB of memory. It would allow for a single instance of Cassandra to run on one node, which is recommended for disk I/O.</p>

<p>Then the pets were deployed! One thousand of them, in two different Cassandra Data Centers. Cassandra distributed architecture is specifically tailored for multiple-data center deployment. Often multiple Cassandra data centers are deployed inside the same physical or virtual data center, in order to separate workloads. Data is replicated across all data centers, but workloads can be different between data centers and thus application tuning can be different. Data centers named ‘DC1-Analytics’ and ‘DC1-Data’ where deployed with 500 pets each. The race data was created by the python Batch Jobs connected to DC1-Data, and the JHipster UI was connected DC1-Analytics.</p>

<p>Here are the final numbers:</p>

<ul>
  <li>8,072 Cores. The master used 24, minion nodes used the rest</li>
  <li>1,009 IP addresses</li>
  <li>1,009 routes setup by Kubernetes on Google Cloud Platform</li>
  <li>100,510 GB persistent disk used by the Minions and the Master</li>
  <li>380,020 GB SSD disk persistent disk. 20 GB for the master and 340 GB per Cassandra Pet.</li>
  <li>1,000 deployed instances of Cassandra Yes we deployed 1,000 pets, but one really did not want to join the party! Technically with the Cassandra setup, we could have lost 333 nodes without service or data loss.</li>
</ul>

<h3 id="limitations-with-pet-sets-in-13-release">Limitations with Pet Sets in 1.3 Release</h3>

<ul>
  <li>Pet Set is an alpha resource not available in any Kubernetes release prior to 1.3.</li>
  <li>The storage for a given pet must either be provisioned by a dynamic storage provisioner based on the requested storage class, or pre-provisioned by an admin.</li>
  <li>Deleting the Pet Set will not delete any pets or Pet storage. You will need to delete your Pets and possibly its storage by hand.</li>
  <li>All Pet Sets currently require a “governing service”, or a Service responsible for the network identity of the pets. The user is responsible for this Service.</li>
  <li>Updating an existing Pet Set is currently a manual process. You either need to deploy a new Pet Set with the new image version or orphan Pets one by one and update their image, which will join them back to the cluster.</li>
</ul>

<h4 id="resources-and-references">Resources and References</h4>

<ul>
  <li>The source code for the demo is available on <a href="https://github.com/k8s-for-greeks/gpmr">GitHub</a>: (Pet Set examples will be merged into the Kubernetes Cassandra Examples).</li>
  <li>More information about <a href="http://kubernetes.io/docs/user-guide/jobs/">Jobs</a></li>
  <li><a href="https://github.com/kubernetes/kubernetes.github.io/blob/release-1.3/docs/user-guide/petset.md">Documentation for Pet Set</a></li>
  <li>Image credits: Cassandra <a href="https://commons.wikimedia.org/wiki/File:Cassandra1.jpeg">image</a> and Cyclops <a href="https://commons.wikimedia.org/wiki/File:Polyphemus.gif">image</a></li>
</ul>

<p><em>– Chris Love, Senior DevOps Open Source Consultant for <a href="https://www.datapipe.com/">Datapipe</a>. <a href="https://twitter.com/chrislovecnm/">Twitter @chrislovecnm</a></em></p>

    </div>
  
    <h1><a href="/blog/2016/07/Kubernetes-In-Rancher-Further-Evolution"> Kubernetes in Rancher: the further evolution </a></h1>
    <p class="author">
      <h2><span class="date-header">July 12 2016</span></h2>
    </p>
    <div class="content">
      <p><em>Editor’s note: today’s guest post is from Alena Prokharchyk, Principal Software Engineer at Rancher Labs, who’ll share how they are incorporating new Kubernetes features into their platform.</em></p>

<p>Kubernetes was the first external orchestration platform supported by <a href="http://rancher.com/kubernetes">Rancher</a>, and since its release, it has become one of the most widely used among our users, and continues to grow rapidly in adoption. As Kubernetes has evolved, so has Rancher in terms of adapting new Kubernetes features. We’ve started with supporting Kubernetes version 1.1, then switched to 1.2 as soon as it was released, and now we’re working on supporting the exciting new features in 1.3. I’d like to walk you through the features that we’ve been adding support for during each of these stages.</p>

<h3 id="rancher-and-kubernetes-12">Rancher and Kubernetes 1.2</h3>

<p>Kubernetes 1.2 introduced enhanced Ingress object to simplify allowing inbound connections to reach the cluster services: here’s an excellent <a href="http://blog.kubernetes.io/2016/03/Kubernetes-1.2-and-simplifying-advanced-networking-with-Ingress.html">blog post about ingress</a> policies. Ingress resource allows users to define host name routing rules and TLS config for the Load Balancer in a user friendly way. Then it should be backed up by an Ingress controller that would configure a corresponding cloud provider’s Load Balancer with the Ingress rules. Since Rancher already included a software defined Load Balancer based on HAproxy, we already supported all of the configuration requirements of the Ingress resource, and didn’t have to do any changes on the Rancher side to adopt Ingress. What we had to do was write an Ingress controller that would listen to Kubernetes ingress specific events, configure the Rancher Load Balancer accordingly, and propagate the Load Balancer public entry point back to Kubernetes:</p>

<p><img src="https://lh3.googleusercontent.com/C8wg_8Vih0evMIAEvCaX3IAbARddxhk5S_Mzv9jdpt87njQR9cbEEGZnFiWrKx7TPm-uPO1V4TP4LDOKvLg7gJ-19-esVMNhbkSf6fXSrbE3nS3Sr45rdP1c-VBuzShgpn9jDCiQ" alt="Screen-Shot-2016-05-13-at-11.15.56-AM.png" /></p>

<p>Now, the ingress controller gets deployed as a part of our Rancher Kubernetes system stack, and is managed by Rancher. Rancher monitors Ingress controller health, and recreates it in case of any failures. In addition to standard ingress features, Rancher also lets you to horizontally scale the Load Balancer supporting the ingress service by specifying scale via Ingress annotations. For example:</p>

<div class="highlighter-rouge">
  <div class="highlight">
    <div class="highlight highlighter-rouge"><div class="highlight"><pre class="highlight"><code>apiVersion: extensions/v1beta1

kind: Ingress

metadata:

 name: scalelb

 annotations:

 scale: "2"

spec:

  rules:

  - host: foo.bar.com

    http:

      paths:

      - path: /foo

        backend:

          serviceName: nginx-service

          servicePort: 80
</code></pre></div>    </div>
  </div>
</div>

<p>As a result of the above, 2 instances of Rancher Load Balancer will get started on separate hosts, and Ingress will get updated with 2 public ip addresses:</p>

<div class="highlighter-rouge">
  <div class="highlight">
    <div class="highlight highlighter-rouge"><div class="highlight"><pre class="highlight"><code>kubectl get ingress

NAME      RULE          BACKEND   ADDRESS

scalelb      -                    104.154.107.202, 104.154.107.203  // hosts ip addresses where Rancher LB instances are deployed

          foo.bar.com

          /foo           nginx-service:80
</code></pre></div>    </div>
  </div>
</div>

<p>More details on Rancher Ingress Controller implementation for Kubernetes can be found here:</p>

<ul>
  <li><a href="http://rancher.com/rancher-controller-for-the-kubernetes-ingress-feature/">Blog post</a></li>
  <li><a href="http://docs.rancher.com/rancher/latest/en/kubernetes/ingress/">Rancher documentation on Ingress</a></li>
  <li><a href="https://github.com/rancher/ingress-controller">Rancher ingress controller repo</a></li>
</ul>

<h3 id="rancher-and-kubernetes-13">Rancher and Kubernetes 1.3</h3>

<p>We’ve very excited about Kubernetes 1.3 release, and all the new features that are included with it. There are two that we are especially interested in: Stateful Apps and Cluster Federation.</p>

<h4 id="kubernetes-stateful-apps">Kubernetes Stateful Apps</h4>

<p>Stateful Apps is a new resource to Kubernetes to represent a set of pods in stateful application. This is an alternative to the using Replication Controllers, which are best leveraged for running stateless apps. This feature is specifically useful for apps that rely on quorum with leader election (such as MongoDB, Zookeeper, etcd) and decentralized quorum (Cassandra). Stateful Apps create and maintains a set of pods, each of which have a stable network identity. In order to provide the network identity, it must be possible to have a resolvable DNS name for the pod that is tied to the pod identity as per <a href="https://github.com/smarterclayton/kubernetes/blob/961f1f94c35d4979ac83bbad482090cb6c22781c/docs/proposals/petset.md">Kubernetes design doc</a>:</p>

<div class="highlighter-rouge">
  <div class="highlight">
    <div class="highlight highlighter-rouge"><div class="highlight"><pre class="highlight"><code># service mongo pointing to pods created by PetSet mdb, with identities mdb-1, mdb-2, mdb-3


dig mongodb.namespace.svc.cluster.local +short A

172.130.16.50


dig mdb-1.mongodb.namespace.svc.cluster.local +short A

# IP of pod created for mdb-1


dig mdb-2.mongodb.namespace.svc.cluster.local +short A

# IP of pod created for mdb-2


dig mdb-3.mongodb.namespace.svc.cluster.local +short A

# IP of pod created for mdb-3
</code></pre></div>    </div>
  </div>
</div>

<p>The above is implemented via an annotation on pods, which is surfaced to endpoints, and finally surfaced as DNS on the service that exposes those pods. Currently Rancher simplifies DNS configuration by leveraging Rancher DNS as a drop-in replacement for SkyDNS. Rancher DNS is fast, stable, and scalable - every host in cluster gets DNS server running. Kubernetes services get programmed to Rancher DNS, and being resolved to either service’s cluster IP from 10,43.x.x address space, or to set of Pod ip addresses for headless service. To make PetSet work with Kubernetes via Rancher, we’ll have to add support for Pod Identities to Rancher DNS configuration. We’re working on this now and should have it supported in one of the upcoming Rancher releases.</p>

<h4 id="cluster-federation">Cluster Federation</h4>
<p>Cluster Federation is a control plane of cluster federation in Kubernetes. It offers improved application availability by spreading applications across multiple clusters (the image below is a courtesy of Kubernetes):</p>

<p><img src="https://lh6.googleusercontent.com/jJjQ6wbYYG1y7rS7SXFNj1dsLrTEBbiOB9TfrkJAqayHVzBZwLguxMB6HLObCgpVGLKF7xdPd3wfdvQzB2a7Cq6cuqqXRRl3L5OfVPwKB34BxdpRUc1g7EgOdEkILH9E4sAfzHyb" alt="Screen Shot 2016-07-07 at 1.46.55 PM.png" /></p>

<p>Each Kubernetes cluster exposes an API endpoint and gets registered to Cluster Federation as a part of Federation object. Then using Cluster Federation API, you can create federated services. Those objects are comprised of multiple equivalent underlying Kubernetes resources. Assuming that the 3 clusters on the picture above belong to the same Federation object, each Service created via Cluster Federation, will get equivalent service created in each of the clusters. Besides that, a Cluster Federation service will get publicly resolvable DNS name resolvable to Kuberentes service’s public ip addresses (DNS record gets programmed to a one of the public DNS providers below):</p>

<p><img src="https://lh6.googleusercontent.com/gmL0eoE2Z_m-KQbidAxrHA_gL8EDoflYuu_DKSxRiSm2RqTde-nYwGD65YBWzZWkCnbEG6NJ_NHCo0oHTP-PxNqWXt7k5Vp76JBOTNawsmlTeehOrPVY6nTZnEMl2ZH0V73_7f9E" alt="Screen Shot 2016-07-07 at 1.24.18 PM.png" /></p>

<p>To support Cluster Federation via Kubernetes in Rancher, certain changes need to be done. Today each Kubernetes cluster is represented as a Rancher environment. In each Kubernetes environment, we create a full Kubernetes system stack comprised of several services: Kubernetes API server, Scheduler, Ingress controller, persistent etcd, Controller manager, Kubelet and Proxy (2 last ones run on every host). To setup Cluster Federation, we will create one extra environment where Cluster Federation stack is going to run:</p>

<p><img src="https://lh6.googleusercontent.com/_76MDeSl_ac2AqN2lvEKgmvrFuV9Mtt9qHngsKKBAy-rcpdMcyo_UyNYdK2z5POoZwBGptVXUoX-11UDHD4axY8Lco15KydIwVd_PlLC0xJ2GZ_-4JN7bkP4pj8SY7mQ4JUXGIL6" alt="Screen Shot 2016-07-07 at 1.23.14 PM.png" /></p>

<p>Then every underlying Kubernetes cluster represented by Rancher environment, should be registered to a specific Cluster Federation. Potentially each cluster can be auto-discovered by Rancher Cluster Federation environment via label representing federation name on Kubernetes cluster. We’re still working through finalizing our design, but we’re very excited by this feature, and see a lot of use cases it can solve. Cluster Federation doc references:</p>

<ul>
  <li>Kubernetes <a href="https://github.com/kubernetes/kubernetes/blob/master/docs/design/federation-phase-1.md">cluster federation design doc</a></li>
  <li>Kubernetes <a href="http://blog.kubernetes.io/2016/03/building-highly-available-applications-using-Kubernetes-new-multi-zone-clusters-a.k.a-Ubernetes-Lite.html">blog post on multi zone clusters</a></li>
  <li>Kubernetes <a href="https://github.com/kubernetes/kubernetes/blob/master/docs/design/federated-services.md">federated services design doc</a></li>
</ul>

<h3 id="plans-for-kubernetes-14">Plans for Kubernetes 1.4</h3>

<p>When we launched Kubernetes support in Rancher we decided to maintain our own distribution of Kubernetes in order to support Rancher’s native networking. We were aware that by having our own distribution, we’d need to update it every time there were changes made to Kubernetes, but we felt it was necessary to support the use cases we were working on for users. As part of our work for 1.4 we looked at our networking approach again, and re-analyzed the initial need for our own fork of Kubernetes. Other than the networking integration, all of the work we’ve done with Kubernetes has been developed as a Kubernetes plugin:</p>

<ul>
  <li>Rancher as a CloudProvider (to support Load Balancers).</li>
  <li>Rancher as a CredentialProvider (to support Rancher private registries).</li>
  <li>Rancher Ingress controller to back up Kubernetes ingress resource.</li>
</ul>

<p>So we’ve decided to eliminate the need of Rancher Kubernetes distribution, and try to upstream all our changes to the Kubernetes repo. To do that, we will be reworking our networking integration, and support Rancher networking as a <a href="http://kubernetes.io/docs/admin/network-plugins/#cni">CNI plugin for Kubernetes</a>. More details on that will be shared as soon as the feature design is finalized, but expect it to come in the next 2-3 months. We will also continue investing in Rancher’s core capabilities integrated with Kubernetes, including, but not limited to:</p>

<ul>
  <li>Access rights management via Rancher environment that represents Kubernetes cluster</li>
  <li>Credential management and easy web-based access to standard kubectl cli</li>
  <li>Load Balancing support</li>
  <li>Rancher internal DNS support</li>
  <li>Catalog support for Kubernetes templates</li>
  <li>Enhanced UI to represent even more Kubernetes objects like: Deployment, Ingress, Daemonset.</li>
</ul>

<p>All of that is to make Kubernetes experience even more powerful and user intuitive. We’re so excited by all of the progress in the Kubernetes community, and thrilled to be participating. Kubernetes 1.3 is an incredibly significant release, and you’ll be able to upgrade to it very soon within Rancher.</p>

<p><em>– Alena Prokharchyk, Principal Software Engineer, Rancher Labs. <a href="https://twitter.com/Lemonjet">Twitter @lemonjet</a> &amp; <a href="https://github.com/alena1108">GitHub alena1108</a></em></p>

<p><img src="https://lh4.googleusercontent.com/isAt46fnmGerA0uPoTUlUS7y5MtmOYfMvKoTC52CK0ckUfFKVO_coY78jgLoQuxe4J3GVf3N2_IWCuKwxpRT6q_h4ek4yepfyWBmN_WSqyB2v7rRaZrpG4hPpuH0hIbIcmTDgUul" alt="Rancher-and-Kubernetes.png" /></p>

    </div>
  
    <h1><a href="/blog/2016/07/Autoscaling-In-Kubernetes"> Autoscaling in Kubernetes </a></h1>
    <p class="author">
      <h2><span class="date-header">July 12 2016</span></h2>
    </p>
    <div class="content">
      <p><em>Editor’s note: this post is part of a <a href="http://blog.kubernetes.io/2016/07/five-days-of-kubernetes-1.3.html">series of in-depth articles</a> on what’s new in Kubernetes 1.3</em></p>

<p>Customers using Kubernetes respond to end user requests quickly and ship software faster than ever before. But what happens when you build a service that is even more popular than you planned for, and run out of compute? In <a href="http://blog.kubernetes.io/2016/07/kubernetes-1.3-bridging-cloud-native-and-enterprise-workloads.html">Kubernetes 1.3</a>, we are proud to announce that we have a solution: autoscaling. On <a href="https://cloud.google.com/compute/">Google Compute Engine</a> (GCE) and <a href="https://cloud.google.com/container-engine/">Google Container Engine</a> (GKE) (and coming soon on <a href="https://aws.amazon.com/">AWS</a>), Kubernetes will automatically scale up your cluster as soon as you need it, and scale it back down to save you money when you don’t.</p>

<h3 id="benefits-of-autoscaling">Benefits of Autoscaling</h3>

<p>To understand better where autoscaling would provide the most value, let’s start with an example. Imagine you have a 24/7 production service with a load that is variable in time, where it is very busy during the day in the US, and relatively low at night. Ideally, we would want the number of nodes in the cluster and the number of pods in deployment to dynamically adjust to the load to meet end user demand. The new Cluster Autoscaling feature together with Horizontal Pod Autoscaler can handle this for you automatically.</p>

<h3 id="setting-up-autoscaling-on-gce">Setting Up Autoscaling on GCE</h3>

<p>The following instructions apply to GCE. For GKE please check the autoscaling section in cluster operations manual available <a href="https://cloud.google.com/container-engine/docs/clusters/operations#create_a_cluster_with_autoscaling">here</a>.</p>

<p>Before we begin, we need to have an active GCE project with Google Cloud Monitoring, Google Cloud Logging and Stackdriver enabled. For more information on project creation, please read our <a href="https://github.com/kubernetes/kubernetes/blob/master/docs/getting-started-guides/gce.md#prerequisites">Getting Started Guide</a>. We also need to download a recent version of Kubernetes project (version <a href="http://v1.3.0/">v1.3.0</a> or later).</p>

<p>First, we set up a cluster with Cluster Autoscaler turned on. The number of nodes in the cluster will start at 2, and autoscale up to a maximum of 5. To implement this, we’ll export the following environment variables:</p>

<div class="highlighter-rouge">
  <div class="highlight">
    <div class="highlight highlighter-rouge"><div class="highlight"><pre class="highlight"><code>export NUM\_NODES=2

export KUBE\_AUTOSCALER\_MIN\_NODES=2

export KUBE\_AUTOSCALER\_MAX\_NODES=5

export KUBE\_ENABLE\_CLUSTER\_AUTOSCALER=true
</code></pre></div>    </div>
  </div>
</div>

<p>and start the cluster by running:</p>

<div class="highlighter-rouge">
  <div class="highlight">
    <div class="highlight highlighter-rouge"><div class="highlight"><pre class="highlight"><code>./cluster/kube-up.sh
</code></pre></div>    </div>
  </div>
</div>

<p>The kube-up.sh script creates a cluster together with Cluster Autoscaler add-on. The autoscaler will try to add new nodes to the cluster if there are pending pods which could schedule on a new node.</p>

<p>Let’s see our cluster, it should have two nodes:</p>

<div class="highlighter-rouge">
  <div class="highlight">
    <div class="highlight highlighter-rouge"><div class="highlight"><pre class="highlight"><code>$ kubectl get nodes

NAME                           STATUS                     AGE

kubernetes-master              Ready,SchedulingDisabled   2m

kubernetes-minion-group-de5q   Ready                      2m

kubernetes-minion-group-yhdx   Ready                      1m
</code></pre></div>    </div>
  </div>
</div>

<h4 id="run--expose-php-apache-server">Run &amp; Expose PHP-Apache Server</h4>

<p>To demonstrate autoscaling we will use a custom docker image based on php-apache server. The image can be found <a href="https://github.com/kubernetes/kubernetes/blob/8caeec429ee1d2a9df7b7a41b21c626346b456fb/docs/user-guide/horizontal-pod-autoscaling/image">here</a>. It defines <a href="https://github.com/kubernetes/kubernetes/blob/8caeec429ee1d2a9df7b7a41b21c626346b456fb/docs/user-guide/horizontal-pod-autoscaling/image/index.php">index.php</a> page which performs some CPU intensive computations.</p>

<p>First, we’ll start a deployment running the image and expose it as a service:</p>

<div class="highlighter-rouge">
  <div class="highlight">
    <div class="highlight highlighter-rouge"><div class="highlight"><pre class="highlight"><code>$ kubectl run php-apache \   

  --image=gcr.io/google\_containers/hpa-example \

  --requests=cpu=500m,memory=500M --expose --port=80  

service "php-apache" createddeployment "php-apache" created
</code></pre></div>    </div>
  </div>
</div>

<p>Now, we will wait some time and verify that both the deployment and the service were correctly created and are running:</p>

<div class="highlighter-rouge">
  <div class="highlight">
    <div class="highlight highlighter-rouge"><div class="highlight"><pre class="highlight"><code>$ kubectl get deployment

NAME         DESIRED   CURRENT   UP-TO-DATE   AVAILABLE   AGE

php-apache   1         1         1            1           49s



$ kubectl get pods  
NAME                          READY     STATUS    RESTARTS   AGE

php-apache-2046965998-z65jn   1/1       Running   0          30s
</code></pre></div>    </div>
  </div>
</div>

<p>We may now check that php-apache server works correctly by calling wget with the service’s address:</p>

<div class="highlighter-rouge">
  <div class="highlight">
    <div class="highlight highlighter-rouge"><div class="highlight"><pre class="highlight"><code>$ kubectl run -i --tty service-test --image=busybox /bin/sh  
Hit enter for command prompt  
$ wget -q -O- http://php-apache.default.svc.cluster.local

OK!
</code></pre></div>    </div>
  </div>
</div>

<h4 id="starting-horizontal-pod-autoscaler">Starting Horizontal Pod Autoscaler</h4>

<p>Now that the deployment is running, we will create a Horizontal Pod Autoscaler for it. To create it, we will use kubectl autoscale command, which looks like this:</p>

<div class="highlighter-rouge">
  <div class="highlight">
    <div class="highlight highlighter-rouge"><div class="highlight"><pre class="highlight"><code>$ kubectl autoscale deployment php-apache --cpu-percent=50 --min=1 --max=10
</code></pre></div>    </div>
  </div>
</div>

<p>This defines a Horizontal Ppod Autoscaler that maintains between 1 and 10 replicas of the Pods controlled by the php-apache deployment we created in the first step of these instructions. Roughly speaking, the horizontal autoscaler will increase and decrease the number of replicas (via the deployment) so as to maintain an average CPU utilization across all Pods of 50% (since each pod requests 500 milli-cores by <a href="https://github.com/kubernetes/kubernetes/blob/8caeec429ee1d2a9df7b7a41b21c626346b456fb/docs/user-guide/horizontal-pod-autoscaling/README.md#kubectl-run">kubectl run</a>, this means average CPU usage of 250 milli-cores). See <a href="https://github.com/kubernetes/kubernetes/blob/8caeec429ee1d2a9df7b7a41b21c626346b456fb/docs/design/horizontal-pod-autoscaler.md#autoscaling-algorithm">here</a> for more details on the algorithm.</p>

<p>We may check the current status of autoscaler by running:</p>

<div class="highlighter-rouge">
  <div class="highlight">
    <div class="highlight highlighter-rouge"><div class="highlight"><pre class="highlight"><code>$ kubectl get hpa

NAME         REFERENCE                     TARGET    CURRENT   MINPODS   MAXPODS   AGE

php-apache   Deployment/php-apache/scale   50%       0%        1         20        14s
</code></pre></div>    </div>
  </div>
</div>

<p>Please note that the current CPU consumption is 0% as we are not sending any requests to the server (the CURRENT column shows the average across all the pods controlled by the corresponding replication controller).</p>

<h4 id="raising-the-load">Raising the Load</h4>

<p>Now, we will see how our autoscalers (Cluster Autoscaler and Horizontal Pod Autoscaler) react on the increased load of the server. We will start two infinite loops of queries to our server (please run them in different terminals):</p>

<div class="highlighter-rouge">
  <div class="highlight">
    <div class="highlight highlighter-rouge"><div class="highlight"><pre class="highlight"><code>$ kubectl run -i --tty load-generator --image=busybox /bin/sh  
Hit enter for command prompt  
$ while true; do wget -q -O- http://php-apache.default.svc.cluster.local; done
</code></pre></div>    </div>
  </div>
</div>

<p>We need to wait a moment (about one minute) for stats to propagate. Afterwards, we will examine status of Horizontal Pod Autoscaler:</p>

<div class="highlighter-rouge">
  <div class="highlight">
    <div class="highlight highlighter-rouge"><div class="highlight"><pre class="highlight"><code>$ kubectl get hpa

NAME         REFERENCE                     TARGET    CURRENT   MINPODS   MAXPODS   AGE

php-apache   Deployment/php-apache/scale   50%       310%      1         20        2m



$ kubectl get deployment php-apache

NAME              DESIRED   CURRENT   UP-TO-DATE   AVAILABLE   AGE

php-apache        7         7         7            3           4m
</code></pre></div>    </div>
  </div>
</div>

<p>Horizontal Pod Autoscaler has increased the number of pods in our deployment to 7. Let’s now check, if all the pods are running:</p>

<div class="highlighter-rouge">
  <div class="highlight">
    <div class="highlight highlighter-rouge"><div class="highlight"><pre class="highlight"><code>jsz@jsz-desk2:~/k8s-src$ kubectl get pods

php-apache-2046965998-3ewo6        0/1       Pending   0          1m

php-apache-2046965998-8m03k        1/1       Running   0          1m

php-apache-2046965998-ddpgp        1/1       Running   0          5m

php-apache-2046965998-lrik6        1/1       Running   0          1m

php-apache-2046965998-nj465        0/1       Pending   0          1m

php-apache-2046965998-tmwg1        1/1       Running   0          1m

php-apache-2046965998-xkbw1        0/1       Pending   0          1m
</code></pre></div>    </div>
  </div>
</div>

<p>As we can see, some pods are pending. Let’s describe one of pending pods to get the reason of the pending state:</p>

<div class="highlighter-rouge">
  <div class="highlight">
    <div class="highlight highlighter-rouge"><div class="highlight"><pre class="highlight"><code>$ kubectl describe pod php-apache-2046965998-3ewo6

Name: php-apache-2046965998-3ewo6

Namespace: default

...

Events:

  FirstSeen From SubobjectPath Type Reason Message



  1m {default-scheduler } Warning FailedScheduling pod (php-apache-2046965998-3ewo6) failed to fit in any node

fit failure on node (kubernetes-minion-group-yhdx): Insufficient CPU

fit failure on node (kubernetes-minion-group-de5q): Insufficient CPU



  1m {cluster-autoscaler } Normal TriggeredScaleUp pod triggered scale-up, mig: kubernetes-minion-group, sizes (current/new): 2/3
</code></pre></div>    </div>
  </div>
</div>

<p>The pod is pending as there was no CPU in the system for it. We see there’s a TriggeredScaleUp event connected with the pod. It means that the pod triggered reaction of Cluster Autoscaler and a new node will be added to the cluster. Now we’ll wait for the reaction (about 3 minutes) and list all nodes:</p>

<div class="highlighter-rouge">
  <div class="highlight">
    <div class="highlight highlighter-rouge"><div class="highlight"><pre class="highlight"><code>$ kubectl get nodes

NAME                           STATUS                     AGE

kubernetes-master              Ready,SchedulingDisabled   9m

kubernetes-minion-group-6z5i   Ready                      43s

kubernetes-minion-group-de5q   Ready                      9m

kubernetes-minion-group-yhdx   Ready                      9m
</code></pre></div>    </div>
  </div>
</div>

<p>As we see a new node kubernetes-minion-group-6z5i was added by Cluster Autoscaler. Let’s verify that all pods are now running:</p>

<div class="highlighter-rouge">
  <div class="highlight">
    <div class="highlight highlighter-rouge"><div class="highlight"><pre class="highlight"><code>$ kubectl get pods

NAME                               READY     STATUS    RESTARTS   AGE

php-apache-2046965998-3ewo6        1/1       Running   0          3m

php-apache-2046965998-8m03k        1/1       Running   0          3m

php-apache-2046965998-ddpgp        1/1       Running   0          7m

php-apache-2046965998-lrik6        1/1       Running   0          3m

php-apache-2046965998-nj465        1/1       Running   0          3m

php-apache-2046965998-tmwg1        1/1       Running   0          3m

php-apache-2046965998-xkbw1        1/1       Running   0          3m
</code></pre></div>    </div>
  </div>
</div>

<p>After the node addition all php-apache pods are running!</p>

<h4 id="stop-load">Stop Load</h4>

<p>We will finish our example by stopping the user load. We’ll terminate both infinite while loops sending requests to the server and verify the result state:</p>

<div class="highlighter-rouge">
  <div class="highlight">
    <div class="highlight highlighter-rouge"><div class="highlight"><pre class="highlight"><code>$ kubectl get hpa

NAME         REFERENCE                     TARGET    CURRENT   MINPODS   MAXPODS   AGE

php-apache   Deployment/php-apache/scale   50%       0%        1         10        16m



$ kubectl get deployment php-apache

NAME              DESIRED   CURRENT   UP-TO-DATE   AVAILABLE   AGE

php-apache        1         1         1            1           14m
</code></pre></div>    </div>
  </div>
</div>

<p>As we see, in the presented case CPU utilization dropped to 0, and the number of replicas dropped to 1.</p>

<p>After deleting pods most of the cluster resources are unused. Scaling the cluster down may take more time than scaling up because Cluster Autoscaler makes sure that the node is really not needed so that short periods of inactivity (due to pod upgrade etc) won’t trigger node deletion (see <a href="https://github.com/kubernetes/kubernetes.github.io/blob/release-1.3/docs/admin/cluster-management.md#cluster-autoscaling">cluster autoscaler doc</a>). After approximately 10-12 minutes you can verify that the number of nodes in the cluster dropped:</p>

<div class="highlighter-rouge">
  <div class="highlight">
    <div class="highlight highlighter-rouge"><div class="highlight"><pre class="highlight"><code>$ kubectl get nodes

NAME                           STATUS                     AGE

kubernetes-master              Ready,SchedulingDisabled   37m

kubernetes-minion-group-de5q   Ready                      36m

kubernetes-minion-group-yhdx   Ready                      36m
</code></pre></div>    </div>
  </div>
</div>

<p>The number of nodes in our cluster is now two again as node kubernetes-minion-group-6z5i was removed by Cluster Autoscaler.</p>

<h3 id="other-use-cases">Other use cases</h3>

<p>As we have shown, it is very easy to dynamically adjust the number of pods to the load using a combination of Horizontal Pod Autoscaler and Cluster Autoscaler.</p>

<p>However Cluster Autoscaler alone can also be quite helpful whenever there are irregularities in the cluster load. For example, clusters related to development or continuous integration tests can be less needed on weekends or at night. Batch processing clusters may have periods when all jobs are over and the new will only start in couple hours. Having machines that do nothing is a waste of money.</p>

<p>In all of these cases Cluster Autoscaler can reduce the number of unused nodes and give quite significant savings because you will only pay for these nodes that you actually need to run your pods. It also makes sure that you always have enough compute power to run your tasks.</p>

<p><em>– Jerzy Szczepkowski and Marcin Wielgus, Software Engineers, Google</em></p>

    </div>
  
    <h1><a href="/blog/2016/07/Rktnetes-Brings-Rkt-Container-Engine-To-Kubernetes"> rktnetes brings rkt container engine to Kubernetes </a></h1>
    <p class="author">
      <h2><span class="date-header">July 11 2016</span></h2>
    </p>
    <div class="content">
      <p><em>Editor’s note: this post is part of a <a href="http://blog.kubernetes.io/2016/07/five-days-of-kubernetes-1.3.html">series of in-depth articles</a> on what’s new in Kubernetes 1.3 </em></p>

<p>As part of <a href="http://blog.kubernetes.io/2016/07/kubernetes-1.3-bridging-cloud-native-and-enterprise-workloads.html">Kubernetes 1.3</a>, we’re happy to report that our work to bring interchangeable container engines to Kubernetes is bearing early fruit. What we affectionately call “rktnetes” is included in the version 1.3 Kubernetes release, and is ready for development use. rktnetes integrates support for <a href="https://coreos.com/rkt/">CoreOS rkt</a> into Kubernetes as the container runtime on cluster nodes, and is now part of the mainline Kubernetes source code. Today it’s easier than ever for developers and ops pros with container portability in mind to try out running Kubernetes with a different container engine.</p>

<p>“We find CoreOS’s rkt a compelling container engine in Kubernetes because of how rkt is composed with the underlying systemd,” said Mark Petrovic, senior MTS and architect at Xoom, a PayPal service. “The rkt runtime assumes only the responsibility it needs to, then delegates to other system services where appropriate. This separation of concerns is important to us.”</p>

<h3 id="whats-rktnetes">What’s rktnetes?</h3>

<p>rktnetes is the nickname given to the code that enables Kubernetes nodes to execute application containers with the rkt container engine, rather than with Docker. This change adds new abilities to Kubernetes, for instance running containers under flexible levels of isolation. rkt explores an alternative approach to container runtime architecture, aimed to reflect the Unix philosophy of cleanly separated, modular tools. Work done to support rktnetes also opens up future possibilities for Kubernetes, such as multiple container image format support, and the integration of other container runtimes tailored for specific use cases or platforms.</p>

<h3 id="why-does-kubernetes-need-rktnetes">Why does Kubernetes need rktnetes?</h3>

<p>rktnetes is about more than just rkt. It’s also about refining and exercising Kubernetes interfaces, and paving the way for other modular runtimes in the future. While the Docker container engine is well known, and is currently the default Kubernetes container runtime, a number of benefits derive from pluggable container environments. Some clusters may call for very specific container engine implementations, for example, and ensuring the Kubernetes design is flexible enough to support alternate runtimes, starting with rkt, helps keep the interfaces between components clean and simple.</p>

<h4 id="separation-of-concerns-decomposing-the-monolithic-container-daemon">Separation of concerns: Decomposing the monolithic container daemon</h4>
<p>The current container runtime used by Kubernetes imposes a number of design decisions. Experimenting with other container execution architectures is worthwhile in such a rapidly evolving space. Today, when Kubernetes sends a request to a node to start running a pod, it communicates through the kubelet on each node with the default container runtime’s central daemon, responsible for managing all of the node’s containers.</p>

<p>rkt does not implement a monolithic container management daemon. (It is worth noting that the <a href="https://blog.docker.com/2016/04/docker-engine-1-11-runc/">default container runtime is in the midst of refactoring its original monolithic architecture</a>.) The rkt design has from day one tried to apply the principle of modularity to the fullest, including reusing well-tested system components, rather than reimplementing them.</p>

<p>The task of building container images is abstracted away from the container runtime core in rkt, and implemented by an independent utility. The same approach is taken to ongoing container lifecycle management. A single binary, rkt, configures the environment and prepares container images for execution, then sets the container application and its isolation environment running. At this point, the rkt program has done its “one job”, and the container isolator takes over.</p>

<p>The API for querying container engine and pod state, used by Kubernetes to track cluster work on each node, is implemented in a separate service, isolating coordination and orchestration features from the core container runtime. While the API service does not fully implement all the API features of the current default container engine, it already helps isolate containers from failures and upgrades in the core runtime, and provides the read-only parts of the expected API for querying container metadata.</p>

<h4 id="modular-container-isolation-levels">Modular container isolation levels</h4>
<p>With rkt managing container execution, Kubernetes can take advantage of the CoreOS container engine’s modular <em>stage1</em> isolation mechanism. The typical container runs under rkt in a software-isolated environment constructed from Linux kernel namespaces, cgroups, and other facilities. Containers isolated in this common way nevertheless share a single kernel with all the other containers on a system, making for lightweight isolation of running apps.</p>

<p>However, rkt features pluggable isolation environments, referred to as stage1s, to change how containers are executed and isolated. For example, the <a href="https://coreos.com/rkt/docs/latest/running-fly-stage1.html">rkt fly stage1</a> runs containers in the host namespaces (PID, mount, network, etc), granting containers greater power on the host system. Fly is used for containerizing lower-level system and network software, like the kubelet itself. At the other end of the isolation spectrum, the <a href="https://coreos.com/rkt/docs/latest/running-lkvm-stage1.html">KVM stage1</a> runs standard app containers as individual virtual machines, each above its own Linux kernel, managed by the KVM hypervisor. This isolation level can be useful for high security and multi-tenant cluster workloads.</p>

<p><a href="https://1.bp.blogspot.com/-k3RRYf70fsg/V4a_-lVypxI/AAAAAAAAAl4/m9lVW0mxw7s35dzLlT4XJO5gdMzy_RBiQCLcB/s1600/rkt%2Bstages.png"><img src="https://1.bp.blogspot.com/-k3RRYf70fsg/V4a_-lVypxI/AAAAAAAAAl4/m9lVW0mxw7s35dzLlT4XJO5gdMzy_RBiQCLcB/s640/rkt%2Bstages.png" alt="" /></a></p>

<p>Currently, rktnetes can use the KVM stage1 to execute all containers on a node with VM isolation by setting the kubelet’s –rkt-stage1-image option. Experimental work exists to choose the stage1 isolation regime on a per-pod basis with a Kubernetes annotation declaring the pod’s appropriate stage1. KVM containers and standard Linux containers can be mixed together in the same cluster.</p>

<h3 id="how-rkt-works-with-kubernetes">How rkt works with Kubernetes</h3>

<p>Kubernetes today talks to the default container engine over an API provided by the Docker daemon. rktnetes communicates with rkt a little bit differently. First, there is a distinction between how Kubernetes changes the state of a node’s containers – how it starts and stops pods, or reschedules them for failover or scaling – and how the orchestrator queries pod metadata for regular, read-only bookkeeping. Two different facilities implement these two different cases.</p>

<p><a href="https://3.bp.blogspot.com/-Agx6uMnddDc/V4bAA2YH_-I/AAAAAAAAAl8/PbKRFjVy0JMqyZ_OJ4oqMtGyTmlFTh0bQCEw/s1600/rktnetes%2B%25281%2529.png"><img src="https://3.bp.blogspot.com/-Agx6uMnddDc/V4bAA2YH_-I/AAAAAAAAAl8/PbKRFjVy0JMqyZ_OJ4oqMtGyTmlFTh0bQCEw/s640/rktnetes%2B%25281%2529.png" alt="" /></a></p>

<h4 id="managing-microservice-lifecycles">Managing microservice lifecycles</h4>
<p>The kubelet on each cluster node communicates with rkt to <a href="https://coreos.com/rkt/docs/latest/subcommands/prepare.html">prepare</a> containers and their environments into pods, and with systemd, the linux service management framework, to invoke and manage the pod processes. Pods are then managed as systemd services, and the kubelet sends systemd commands over dbus to manipulate them. Lifecycle management, such as restarting failed pods and killing completed processes, is handled by systemd, at the kubelet’s behest.</p>

<h4 id="the-api-service-for-reading-pod-data">The API service for reading pod data</h4>
<p>A discrete <a href="https://coreos.com/rkt/docs/latest/subcommands/api-service.html">rkt api-service</a> implements the pod introspection mechanisms expected by Kubernetes. While each node’s kubelet uses systemd to start, stop, and restart pods as services, it contacts the API service to read container runtime metadata. This includes basic orchestration information such as the number of pods running on the node, the names and networks of those pods, and the details of pod configuration, resource limits and storage volumes (think of the information shown by the kubectl describe subcommand).</p>

<p>Pod logs, having been written to journal files, are made available for kubectl logs and other forensic subcommands by the API service as well, which reads from log files to provide pod log data to the kubelet for answering control plane requests.</p>

<p>This dual interface to the container environment is an area of very active development, and plans are for the API service to expand to provide methods for the pod manipulation commands. The underlying mechanism will continue to keep separation of concerns in mind, but will hide more of this from the kubelet. The methods the kubelet uses to control the rktnetes container engine will grow less different from the default container runtime interface over time.</p>

<h3 id="try-rktnetes">Try rktnetes</h3>

<p>So what can you do with rktnetes today? Currently, rktnetes passes all of <a href="http://storage.googleapis.com/kubernetes-test-history/static/suite-rktnetes:kubernetes-e2e-gce.html">the applicable Kubernetes “end-to-end” (aka “e2e”) tests</a>, provides standard metrics to cAdvisor, manages networks using <a href="https://github.com/containernetworking/cni">CNI</a>, handles per-container/pod logs, and automatically garbage collects old containers and images. Kubernetes running on rkt already provides more than the basics of a modular, flexible container runtime for Kubernetes clusters, and it is already a functional part of our development environment at CoreOS.</p>

<p>Developers and early adopters can follow the known issues in the <a href="http://kubernetes.io/docs/getting-started-guides/rkt/notes/">rktnetes notes</a> to get an idea  of the wrinkles and bumps test-drivers can expect to encounter. This list groups the high-level pieces required to bring rktnetes to feature parity with the existing container runtime and API. We hope you’ll try out rktnetes in your Kubernetes clusters, too.</p>

<h4 id="use-rkt-with-kubernetes-today">Use rkt with Kubernetes Today</h4>
<p>The introductory guide <a href="http://kubernetes.io/docs/getting-started-guides/rkt/"><em>Running Kubernetes on rkt</em></a> walks through the steps to spin up a rktnetes cluster, from kubelet –container-runtime=rkt to networking and starting pods. This intro also sketches the configuration you’ll need to start a cluster on GCE with the Kubernetes kube-up.sh script.</p>

<p>Recent work aims to make rktnetes cluster creation much easier, too. While not yet merged, an <a href="https://github.com/coreos/coreos-kubernetes/pull/551">in-progress pull request creates a single rktnetes configuration toggle</a> to select rkt as the container engine when deploying a Kubernetes cluster with the <a href="https://github.com/coreos/coreos-kubernetes#kubernetes-on-coreos">coreos-kubernetes</a> configuration tools. You can also check out the <a href="https://github.com/coreos/rkt8s-workshop">rktnetes workshop project</a>, which launches a single-node rktnetes cluster on just about any developer workstation with one vagrant up command.</p>

<p>We’re excited to see the experiments the wider Kubernetes and CoreOS communities devise to put rktnetes to the test, and we welcome your input – and pull requests!</p>

<p><em>–Yifan Gu and Josh Wood, rktnetes Team, <a href="https://coreos.com/">CoreOS</a>. Twitter <a href="https://twitter.com/coreoslinux">@CoreOSLinux</a>.</em></p>

    </div>
  
    <h1><a href="/blog/2016/07/Minikube-Easily-Run-Kubernetes-Locally"> Minikube: easily run Kubernetes locally  </a></h1>
    <p class="author">
      <h2><span class="date-header">July 11 2016</span></h2>
    </p>
    <div class="content">
      <p><em>Editor’s note: This is the first post in a <a href="http://blog.kubernetes.io/2016/07/five-days-of-kubernetes-1.3.html">series of in-depth articles</a> on what’s new in Kubernetes 1.3 </em></p>

<p>While Kubernetes is one of the best tools for managing containerized applications available today, and has been production-ready for over a year, Kubernetes has been missing a great local development platform.</p>

<p>For the past several months, several of us from the Kubernetes community have been working to fix this in the <a href="http://github.com/kubernetes/minikube">Minikube</a> repository on GitHub. Our goal is to build an easy-to-use, high-fidelity Kubernetes distribution that can be run locally on Mac, Linux and Windows workstations and laptops with a single command.</p>

<p>Thanks to lots of help from members of the community, we’re proud to announce the official release of Minikube. This release comes with support for <a href="http://blog.kubernetes.io/2016/07/kubernetes-1.3-bridging-cloud-native-and-enterprise-workloads.html">Kubernetes 1.3</a>, new commands to make interacting with your local cluster easier and experimental drivers for xhyve (on Mac OSX) and KVM (on Linux).</p>

<p><strong>Using Minikube</strong></p>

<p>Minikube ships as a standalone Go binary, so installing it is as simple as downloading Minikube and putting it on your path:</p>

<p>Minikube currently requires that you have VirtualBox installed, which you can download <a href="https://www.virtualbox.org/">here</a>.</p>

<p><em>(This is for Mac, for Linux substitute “minikube-darwin-amd64” with “minikube-linux-amd64”)_curl -Lo minikube https://storage.googleapis.com/minikube/releases/latest/minikube-darwin-amd64 &amp;&amp; chmod +x minikube &amp;&amp; sudo mv minikube /usr/local/bin/</em></p>

<p>To start a Kubernetes cluster in Minikube, use the <code class="highlighter-rouge">minikube start</code> command:</p>

<div class="highlighter-rouge">
  <div class="highlight">
    <div class="highlight highlighter-rouge"><div class="highlight"><pre class="highlight"><code>$ minikube start

Starting local Kubernetes cluster...

Kubernetes is available at https://192.168.99.100:443

Kubectl is now configured to use the cluster
</code></pre></div>    </div>
  </div>
</div>

<p><img src="https://lh5.googleusercontent.com/UNRbuyrACtW32dxMehR7GaQlj4CaVxVmlw3UhTqzyIDBgENdT1PcXf-3RoW-T1PFhIQtBbIPq1p544NAKFMO_E_1BUx7MBpkRyw6URtv4W0xT-O4tyWDYJf3MYna6a_8cFJnVvXZ" alt="" /></p>

<p>At this point, you have a running single-node Kubernetes cluster on your laptop! Minikube also configures <code class="highlighter-rouge">kubectl</code> for you, so you’re also ready to run containers with no changes.</p>

<p>Minikube creates a Host-Only network interface that routes to your node. To interact with running pods or services, you should send traffic over this address. To find out this address, you can use the <code class="highlighter-rouge">minikube ip</code> command:</p>

<p><img src="https://lh4.googleusercontent.com/Qm-FoMGXGTlyhiM9jzuH6HE3497ZH19gjDMZrkNVhrlJzi9KQXlGCPoWbss-Hxa3fSBTbgxVZYjUpK-EG4rSinHHGz-7xH9e0QsmE72gX6Mzn5FihvFBfeF6_pJugd1GT0Gzp5qb" alt="" /></p>

<p>Minikube also comes with the Kubernetes Dashboard. To open this up in your browser, you can use the built-in <code class="highlighter-rouge">minikube dashboard</code> command:</p>

<p><img src="https://lh5.googleusercontent.com/PZOe7HAMTJoO_U-r6mR8bXJc7pRIaw33BSQ_SafMY-DPSJB5tiw9SooUvCbtOCJEqQqvnHqngDfFJwWy9Oj3svyo8oTQnzy5srKwZEcBh7fm44n_9YImeJEGhvfNVnx0cfjZ7mcU" alt="" /></p>

<p><img src="https://lh3.googleusercontent.com/fshhlXr1e39gsMKWbVUGb7rrGcy4uP44ML3Jt7-Sr3ZryoMw802xpkAMaz7ayjQNGtAYl3wpKJgwfefuug1FWHbinr1usN9jwFIAJFKeVeZxaiKtalHXP322_D5otR0Asvw6MUD_" alt="" class="big-img" /></p>

<p>In general, Minikube supports everything you would expect from a Kubernetes cluster. You can use <code class="highlighter-rouge">kubectl exec</code> to get a bash shell inside a pod in your cluster. You can use the <code class="highlighter-rouge">kubectl port-forward</code> and <code class="highlighter-rouge">kubectl proxy</code> commands to forward traffic from localhost to a pod or the API server.</p>

<p>Since Minikube is running locally instead of on a cloud provider, certain provider-specific features like LoadBalancers and PersistentVolumes will not work out-of-the-box. However, you can use NodePort LoadBalancers and HostPath PersistentVolumes.</p>

<p><strong>Architecture</strong></p>

<p>Minikube is built on top of Docker’s <a href="https://github.com/docker/machine/tree/master/libmachine">libmachine</a>, and leverages the driver model to create, manage and interact with locally-run virtual machines.</p>

<p><a href="https://redspread.com/">RedSpread</a> was kind enough to donate their <a href="https://github.com/redspread/localkube">localkube</a> codebase to the Minikube repo, which we use to spin up a single-process Kubernetes cluster inside a VM. Localkube bundles etcd, DNS, the Kubelet and all the Kubernetes master components into a single Go binary, and runs them all via separate goroutines.</p>

<p><strong>Upcoming Features</strong></p>

<p>Minikube has been a lot of fun to work on so far, and we’re always looking to improve Minikube to make the Kubernetes development experience better. If you have any ideas for features, don’t hesitate to let us know in the <a href="https://github.com/kubernetes/minikube/issues">issue tracker</a>. </p>

<p>Here’s a list of some of the things we’re hoping to add to Minikube soon:</p>

<ul>
  <li>Native hypervisor support for OSX and Windows</li>
  <li>We’re planning to remove the dependency on Virtualbox, and integrate with the native hypervisors included in OSX and Windows (Hypervisor.framework and Hyper-v, respectively).</li>
  <li>Improved support for Kubernetes features</li>
  <li>We’re planning to increase the range of supported Kubernetes features, to include things like Ingress.</li>
  <li>Configurable versions of Kubernetes</li>
  <li>Today Minikube only supports Kubernetes 1.3. We’re planning to add support for user-configurable versions of Kubernetes, to make it easier to match what you have running in production on your laptop.</li>
</ul>

<p><strong>Community</strong></p>

<p>We’d love to hear feedback on Minikube. To join the community:</p>

<ul>
  <li>Post issues or feature requests on <a href="https://github.com/kubernetes/minikube">GitHub</a></li>
  <li>Join us in the #minikube channel on <a href="https://kubernetes.slack.com/">Slack</a></li>
</ul>

<p>Please give Minikube a try, and let us know how it goes!</p>

<p><em>–Dan Lorenc, Software Engineer, Google</em></p>

    </div>
  
    <h1><a href="/blog/2016/07/Five-Days-Of-Kubernetes-1.3"> Five Days of Kubernetes 1.3 </a></h1>
    <p class="author">
      <h2><span class="date-header">July 11 2016</span></h2>
    </p>
    <div class="content">
      <p>Last week we <a href="http://blog.kubernetes.io/2016/07/kubernetes-1.3-bridging-cloud-native-and-enterprise-workloads.html">released Kubernetes 1.3</a>, two years from the day when the first Kubernetes commit was pushed to GitHub. Now 30,000+ commits later from over 800 contributors, this 1.3 releases is jam packed with updates driven by feedback from users.</p>

<p>While many new improvements and features have been added in the latest release, we’ll be highlighting several that stand-out. Follow along and read these in-depth posts on what’s new and how we continue to make Kubernetes the best way to manage containers at scale. </p>

<p>| Day 1 |</p>

<p>* <a href="http://blog.kubernetes.io/2016/07/minikube-easily-run-kubernetes-locally.html">Minikube: easily run Kubernetes locally</a> * <a href="http://blog.kubernetes.io/2016/07/rktnetes-brings-rkt-container-engine-to-Kubernetes.html">rktnetes: brings rkt container engine to Kubernetes</a> | | Day 2 | * <a href="http://blog.kubernetes.io/2016/07/autoscaling-in-kubernetes.html">Autoscaling in Kubernetes</a><br /> * <em>Partner post: <a href="http://blog.kubernetes.io/2016/07/kubernetes-in-rancher-further-evolution.html">Kubernetes in Rancher, the further evolution</a></em> | | Day 3 | * <a href="http://blog.kubernetes.io/2016/07/thousand-instances-of-cassandra-using-kubernetes-pet-set.html">Deploying thousand instances of Cassandra using Pet Set</a><br /> * <em>Partner post: <a href="http://blog.kubernetes.io/2016/07/stateful-applications-in-containers-kubernetes.html">Stateful Applications in Containers, by Diamanti</a></em> | | Day 4 | * <a href="http://blog.kubernetes.io/2016/07/cross-cluster-services.html">Cross Cluster Services</a><br /> <em>* Partner post: <a href="http://blog.kubernetes.io/2016/07/Citrix-NetScaler-and-Kubernetes.html">Citrix and NetScaler CPX</a></em> | | Day 5 | * <a href="http://blog.kubernetes.io/2016/07/dashboard-web-interface-for-kubernetes.html">Dashboard - Full Featured Web Interface for Kubernetes</a><br /> * <em>Partner post: <a href="http://blog.kubernetes.io/2016/07/automation-platform-at-wercker-with-kubernetes.html">Steering an Automation Platform at Wercker with Kubernetes</a></em> | | Bonus | * <a href="http://blog.kubernetes.io/2016/07/kubernetes-updates-to-performance-and-scalability-in-1.3.html">Updates to Performance and Scalability</a> |</p>

<p><strong>Connect</strong></p>

<p>We’d love to hear from you and see you participate in this growing community:</p>

<ul>
  <li>Get involved with the Kubernetes project on <a href="https://github.com/kubernetes/kubernetes">GitHub</a> </li>
  <li>Post questions (or answer questions) on <a href="https://stackoverflow.com/questions/tagged/kubernetes">Stackoverflow</a> </li>
  <li>Connect with the community on <a href="http://slack.kubernetes.io/">Slack</a></li>
  <li>Follow us on Twitter <a href="https://twitter.com/kubernetesio">@Kubernetesio</a> for latest updates</li>
</ul>

    </div>
  

  <!-- Pagination links -->
  <div class="col-xs-6 col-sm-6 col-md-10 col-lg-10 pagination">
    
     <a href="/blog/page16/" class="previous button pagerButton left">  <h4>  &laquo; Prev</h4></a>
    
    <h4 class="pagination" ><span class="page_number">   Page 17 of 29   </span></h4>
    
      <a href="/blog/page18/" class="next button pagerButton right"><h4>Next  &raquo;</h4></a>
    
  </div>


        <div class="PageNavigation">
          <div class="pagerButton left">
            
          </div>

          <div class="pagerButton right">
            
          </div>




        </div>
    </div>


    <div class="col-xs-1 col-sm-1 col-sm-3 col-lg-3 text">
      <div ="widget-content">
        <link href='http://kubernetes.io/feed.xml' rel='alternate' type='application/atom+xml'>
        <a class="widget-link" href="https://kubernetes.io/feed.xml"> <i class="fas fa-rss fab-icon"> </i> </a>
        <a class="widget-link" href="https://twitter.com/kubernetesio"> <i class="fab fa-twitter-square fab-icon"> </i> @Kubernetesio</a>
        <a class="widget-link" href="https://github.com/kubernetes/kubernetes"> <i class="fab fa-github-square fab-icon"></i> View on Github </a>
        <a class="widget-link" href="http://slack.k8s.io"><i class="fab fa-slack fab-icon"> </i> #kubernetes-users </a>
        <a class="widget-link" href="http://stackoverflow.com/questions/tagged/kubernetes"><i class="fab fa-stack-overflow fab-icon"></i>Stack Overflow</a>
        <a class="widget-link" href="http://get.k8s.io/"><i class="fab fa-stack-overflow fab-icon"></i>Download Kubernetes</a>
      </div>

<!-- Begin Sidebar  Loop -->
    
    
    
    
    
    
    <div class="sidebar-current-year">
    <h4 id="2018-ref">2018</h4>
    <!-- Here we open a div and ul that are conditionally closed in the lower blocks -->
    <div>
      <h4 id="2018-April-ref">April</h4>
      <ul>
        
        <li><a href="/blog/2018/04/11/migrating-the-kubernetes-blog/">Migrating the Kubernetes blog</a></li>
      
        
              
        
    

    
    
    
    
    
        <li><a href="/blog/2018/04/10/container-storage-interface-beta/">Container Storage Interface (CSI) for Kubernetes Goes Beta</a></li>
      
        
              
        
    

    
    
    
    
    
        <li><a href="/blog/2018/04/04/fixing-subpath-volume-vulnerability/">Fixing the Subpath Volume Vulnerability in Kubernetes</a></li>
      
        
              
              </ul>


              <input type="checkbox" id="2018-March-ref-checkbox" class="heading-month-toggle-checkbox"/>
              <label class="collapsible-month-heading-label" for="2018-March-ref-checkbox">
                <span class="collapsible-posts-list-caret">►&nbsp;</span>
                <h5 class="collapsible-month-header" id="2018-March-ref">March</h5>
              </label>

              <ul class="collapsible-posts-list">
            
        
    

    
    
    
    
    
        <li><a href="/blog/2018/03/26/kubernetes-1.10-stabilizing-storage-security-networking/">Kubernetes 1.10: Stabilizing Storage, Security, and Networking </a></li>
      
        
              
        
    

    
    
    
    
    
        <li><a href="/blog/2018/03/Principles-Of-Container-App-Design">Principles of Container-based Application Design</a></li>
      
        
              
        
    

    
    
    
    
    
        <li><a href="/blog/2018/03/Expanding-User-Support-With-Office-Hours">Expanding User Support with Office Hours</a></li>
      
        
              
        
    

    
    
    
    
    
        <li><a href="/blog/2018/03/How-To-Integrate-Rollingupdate-Strategy">How to Integrate RollingUpdate Strategy for TPR in Kubernetes</a></li>
      
        
              
        
    

    
    
    
    
    
        <li><a href="/blog/2018/03/Apache-Spark-23-With-Native-Kubernetes">Apache Spark 2.3 with Native Kubernetes Support</a></li>
      
        
              
        
    

    
    
    
    
    
        <li><a href="/blog/2018/03/First-Beta-Version-Of-Kubernetes-1-10">Kubernetes: First Beta Version of Kubernetes 1.10 is Here</a></li>
      
        
              
              </ul>


              <input type="checkbox" id="2018-January-ref-checkbox" class="heading-month-toggle-checkbox"/>
              <label class="collapsible-month-heading-label" for="2018-January-ref-checkbox">
                <span class="collapsible-posts-list-caret">►&nbsp;</span>
                <h5 class="collapsible-month-header" id="2018-January-ref">January</h5>
              </label>

              <ul class="collapsible-posts-list">
            
        
    

    
    
    
    
    
        <li><a href="/blog/2018/01/Reporting-Errors-Using-Kubernetes-Events">Reporting Errors from Control Plane to Applications Using Kubernetes Events</a></li>
      
        
              
        
    

    
    
    
    
    
        <li><a href="/blog/2018/01/Core-Workloads-Api-Ga">Core Workloads API GA</a></li>
      
        
              
        
    

    
    
    
    
    
        <li><a href="/blog/2018/01/Introducing-Client-Go-Version-6">Introducing client-go version 6</a></li>
      
        
              
        
    

    
    
    
    
    
        <li><a href="/blog/2018/01/Extensible-Admission-Is-Beta">Extensible Admission is Beta</a></li>
      
        
              
        
    

    
    
    
    
    
        <li><a href="/blog/2018/01/Introducing-Container-Storage-Interface"> Introducing Container Storage Interface (CSI) Alpha for Kubernetes </a></li>
      
        
              
        
    

    
    
    
    
    
        <li><a href="/blog/2018/01/Kubernetes-V19-Beta-Windows-Support">Kubernetes v1.9 releases beta support for Windows Server Containers</a></li>
      
        
              
        
    

    
    
    
    
    
        <li><a href="/blog/2018/01/Five-Days-Of-Kubernetes-19"> Five Days of Kubernetes 1.9 </a></li>
      
        
          </ul>
          <!-- this closes the collapsible year body -->
        </div>
        <!-- this closes the sidebar-previous-year opened below -->
      </div>
      <div class="sidebar-previous-year">
        <input type="checkbox" id="2017-ref-checkbox" class="heading-year-toggle-checkbox"/>
        <label class="collapsible-year-heading-label" for="2017-ref-checkbox">
          <span class="collapsible-year-body-caret">►&nbsp;</span>
          <h4 class="collapsible-year-header" id="2017-ref">2017</h4>
        </label>
        <div class="collapsible-year-body">
          <input type="checkbox" id="2017-December-ref-checkbox" class="heading-month-toggle-checkbox"/>
          <label class="collapsible-month-heading-label" for="2017-December-ref-checkbox">
            <span class="collapsible-posts-list-caret">►&nbsp;</span>
            <h5 class="collapsible-month-header" id="2017-December-ref">December</h5>
          </label>
          <ul class="collapsible-posts-list">
            
    

    
    
    
    
    
        <li><a href="/blog/2017/12/Introducing-Kubeflow-Composable"> Introducing Kubeflow - A Composable, Portable, Scalable ML Stack Built for Kubernetes </a></li>
      
        
              
        
    

    
    
    
    
    
        <li><a href="/blog/2017/12/Kubernetes-19-Workloads-Expanded-Ecosystem"> Kubernetes 1.9: Apps Workloads GA and Expanded Ecosystem </a></li>
      
        
              
        
    

    
    
    
    
    
        <li><a href="/blog/2017/12/Using-Ebpf-In-Kubernetes">Using eBPF in Kubernetes</a></li>
      
        
              
        
    

    
    
    
    
    
        <li><a href="/blog/2017/12/Paddle-Paddle-Fluid-Elastic-Learning"> PaddlePaddle Fluid: Elastic Deep Learning on Kubernetes </a></li>
      
        
              
              </ul>


              <input type="checkbox" id="2017-November-ref-checkbox" class="heading-month-toggle-checkbox"/>
              <label class="collapsible-month-heading-label" for="2017-November-ref-checkbox">
                <span class="collapsible-posts-list-caret">►&nbsp;</span>
                <h5 class="collapsible-month-header" id="2017-November-ref">November</h5>
              </label>

              <ul class="collapsible-posts-list">
            
        
    

    
    
    
    
    
        <li><a href="/blog/2017/11/Autoscaling-In-Kubernetes"> Autoscaling in Kubernetes </a></li>
      
        
              
        
    

    
    
    
    
    
        <li><a href="/blog/2017/11/Certified-Kubernetes-Conformance"> Certified Kubernetes Conformance Program: Launch Celebration Round Up </a></li>
      
        
              
        
    

    
    
    
    
    
        <li><a href="/blog/2017/11/Kubernetes-Is-Still-Hard-For-Developers"> Kubernetes is Still Hard (for Developers) </a></li>
      
        
              
        
    

    
    
    
    
    
        <li><a href="/blog/2017/11/Securing-Software-Supply-Chain-Grafeas"> Securing Software Supply Chain with Grafeas </a></li>
      
        
              
        
    

    
    
    
    
    
        <li><a href="/blog/2017/11/Containerd-Container-Runtime-Options-Kubernetes">  Containerd Brings More Container Runtime Options for Kubernetes </a></li>
      
        
              
        
    

    
    
    
    
    
        <li><a href="/blog/2017/11/Kubernetes-Easy-Way"> Kubernetes the Easy Way </a></li>
      
        
              
              </ul>


              <input type="checkbox" id="2017-October-ref-checkbox" class="heading-month-toggle-checkbox"/>
              <label class="collapsible-month-heading-label" for="2017-October-ref-checkbox">
                <span class="collapsible-posts-list-caret">►&nbsp;</span>
                <h5 class="collapsible-month-header" id="2017-October-ref">October</h5>
              </label>

              <ul class="collapsible-posts-list">
            
        
    

    
    
    
    
    
        <li><a href="/blog/2017/10/Enforcing-Network-Policies-In-Kubernetes"> Enforcing Network Policies in Kubernetes </a></li>
      
        
              
        
    

    
    
    
    
    
        <li><a href="/blog/2017/10/Using-Rbac-Generally-Available-18"> Using RBAC, Generally Available in Kubernetes v1.8 </a></li>
      
        
              
        
    

    
    
    
    
    
        <li><a href="/blog/2017/10/It-Takes-Village-To-Raise-Kubernetes"> It Takes a Village to Raise a Kubernetes </a></li>
      
        
              
        
    

    
    
    
    
    
        <li><a href="/blog/2017/10/Kubeadm-V18-Released">  kubeadm v1.8 Released: Introducing Easy Upgrades for Kubernetes Clusters </a></li>
      
        
              
        
    

    
    
    
    
    
        <li><a href="/blog/2017/10/Five-Days-Of-Kubernetes-18"> Five Days of Kubernetes 1.8 </a></li>
      
        
              
        
    

    
    
    
    
    
        <li><a href="/blog/2017/10/Software-Conformance-Certification"> Introducing Software Certification for Kubernetes </a></li>
      
        
              
        
    

    
    
    
    
    
        <li><a href="/blog/2017/10/Request-Routing-And-Policy-Management"> Request Routing and Policy Management with the Istio Service Mesh </a></li>
      
        
              
        
    

    
    
    
    
    
        <li><a href="/blog/2017/10/Kubernetes-Community-Steering-Committee-Election-Results"> Kubernetes Community Steering Committee Election Results </a></li>
      
        
              
              </ul>


              <input type="checkbox" id="2017-September-ref-checkbox" class="heading-month-toggle-checkbox"/>
              <label class="collapsible-month-heading-label" for="2017-September-ref-checkbox">
                <span class="collapsible-posts-list-caret">►&nbsp;</span>
                <h5 class="collapsible-month-header" id="2017-September-ref">September</h5>
              </label>

              <ul class="collapsible-posts-list">
            
        
    

    
    
    
    
    
        <li><a href="/blog/2017/09/Kubernetes-18-Security-Workloads-And"> Kubernetes 1.8: Security, Workloads and Feature Depth </a></li>
      
        
              
        
    

    
    
    
    
    
        <li><a href="/blog/2017/09/Kubernetes-Statefulsets-Daemonsets"> Kubernetes StatefulSets & DaemonSets Updates </a></li>
      
        
              
        
    

    
    
    
    
    
        <li><a href="/blog/2017/09/Introducing-Resource-Management-Working"> Introducing the Resource Management Working Group </a></li>
      
        
              
        
    

    
    
    
    
    
        <li><a href="/blog/2017/09/Windows-Networking-At-Parity-With-Linux"> Windows Networking at Parity with Linux for Kubernetes </a></li>
      
        
              
              </ul>


              <input type="checkbox" id="2017-August-ref-checkbox" class="heading-month-toggle-checkbox"/>
              <label class="collapsible-month-heading-label" for="2017-August-ref-checkbox">
                <span class="collapsible-posts-list-caret">►&nbsp;</span>
                <h5 class="collapsible-month-header" id="2017-August-ref">August</h5>
              </label>

              <ul class="collapsible-posts-list">
            
        
    

    
    
    
    
    
        <li><a href="/blog/2017/08/Kubernetes-Meets-High-Performance"> Kubernetes Meets High-Performance Computing </a></li>
      
        
              
        
    

    
    
    
    
    
        <li><a href="/blog/2017/08/High-Performance-Networking-With-Ec2"> High Performance Networking with EC2 Virtual Private Clouds </a></li>
      
        
              
        
    

    
    
    
    
    
        <li><a href="/blog/2017/08/Kompose-Helps-Developers-Move-Docker"> Kompose Helps Developers Move Docker Compose Files to Kubernetes </a></li>
      
        
              
              </ul>


              <input type="checkbox" id="2017-July-ref-checkbox" class="heading-month-toggle-checkbox"/>
              <label class="collapsible-month-heading-label" for="2017-July-ref-checkbox">
                <span class="collapsible-posts-list-caret">►&nbsp;</span>
                <h5 class="collapsible-month-header" id="2017-July-ref">July</h5>
              </label>

              <ul class="collapsible-posts-list">
            
        
    

    
    
    
    
    
        <li><a href="/blog/2017/07/Happy-Second-Birthday-Kubernetes"> Happy Second Birthday: A Kubernetes Retrospective </a></li>
      
        
              
        
    

    
    
    
    
    
        <li><a href="/blog/2017/07/How-Watson-Health-Cloud-Deploys"> How Watson Health Cloud Deploys Applications with Kubernetes </a></li>
      
        
              
              </ul>


              <input type="checkbox" id="2017-June-ref-checkbox" class="heading-month-toggle-checkbox"/>
              <label class="collapsible-month-heading-label" for="2017-June-ref-checkbox">
                <span class="collapsible-posts-list-caret">►&nbsp;</span>
                <h5 class="collapsible-month-header" id="2017-June-ref">June</h5>
              </label>

              <ul class="collapsible-posts-list">
            
        
    

    
    
    
    
    
        <li><a href="/blog/2017/06/Kubernetes-1.7-Security-Hardening-Stateful-Application-Extensibility-Updates"> Kubernetes 1.7: Security Hardening, Stateful Application Updates and Extensibility </a></li>
      
        
              
              </ul>


              <input type="checkbox" id="2017-May-ref-checkbox" class="heading-month-toggle-checkbox"/>
              <label class="collapsible-month-heading-label" for="2017-May-ref-checkbox">
                <span class="collapsible-posts-list-caret">►&nbsp;</span>
                <h5 class="collapsible-month-header" id="2017-May-ref">May</h5>
              </label>

              <ul class="collapsible-posts-list">
            
        
    

    
    
    
    
    
        <li><a href="/blog/2017/05/Managing-Microservices-With-Istio-Service-Mesh">  Managing microservices with the Istio service mesh </a></li>
      
        
              
        
    

    
    
    
    
    
        <li><a href="/blog/2017/05/Draft-Kubernetes-Container-Development"> Draft: Kubernetes container development made easy </a></li>
      
        
              
        
    

    
    
    
    
    
        <li><a href="/blog/2017/05/Kubespray-Ansible-Collaborative-Kubernetes-Ops"> Kubespray Ansible Playbooks foster Collaborative Kubernetes Ops </a></li>
      
        
              
        
    

    
    
    
    
    
        <li><a href="/blog/2017/05/Kubernetes-Monitoring-Guide"> Kubernetes: a monitoring guide </a></li>
      
        
              
        
    

    
    
    
    
    
        <li><a href="/blog/2017/05/Kubernetes-Security-Process-Explained"> Dancing at the Lip of a Volcano: The Kubernetes Security Process - Explained </a></li>
      
        
              
              </ul>


              <input type="checkbox" id="2017-April-ref-checkbox" class="heading-month-toggle-checkbox"/>
              <label class="collapsible-month-heading-label" for="2017-April-ref-checkbox">
                <span class="collapsible-posts-list-caret">►&nbsp;</span>
                <h5 class="collapsible-month-header" id="2017-April-ref">April</h5>
              </label>

              <ul class="collapsible-posts-list">
            
        
    

    
    
    
    
    
        <li><a href="/blog/2017/04/Multi-Stage-Canary-Deployments-With-Kubernetes-In-The-Cloud-Onprem"> How Bitmovin is Doing Multi-Stage Canary Deployments with Kubernetes in the Cloud and On-Prem </a></li>
      
        
              
        
    

    
    
    
    
    
        <li><a href="/blog/2017/04/Rbac-Support-In-Kubernetes"> RBAC Support in Kubernetes </a></li>
      
        
              
        
    

    
    
    
    
    
        <li><a href="/blog/2017/04/Configuring-Private-Dns-Zones-Upstream-Nameservers-Kubernetes"> Configuring Private DNS Zones and Upstream Nameservers in Kubernetes </a></li>
      
        
              
              </ul>


              <input type="checkbox" id="2017-March-ref-checkbox" class="heading-month-toggle-checkbox"/>
              <label class="collapsible-month-heading-label" for="2017-March-ref-checkbox">
                <span class="collapsible-posts-list-caret">►&nbsp;</span>
                <h5 class="collapsible-month-header" id="2017-March-ref">March</h5>
              </label>

              <ul class="collapsible-posts-list">
            
        
    

    
    
    
    
    
        <li><a href="/blog/2017/03/Advanced-Scheduling-In-Kubernetes"> Advanced Scheduling in Kubernetes </a></li>
      
        
              
        
    

    
    
    
    
    
        <li><a href="/blog/2017/03/Scalability-Updates-In-Kubernetes-1.6"> Scalability updates in Kubernetes 1.6: 5,000 node and 150,000 pod clusters </a></li>
      
        
              
        
    

    
    
    
    
    
        <li><a href="/blog/2017/03/Five-Days-Of-Kubernetes-1.6"> Five Days of Kubernetes 1.6 </a></li>
      
        
              
        
    

    
    
    
    
    
        <li><a href="/blog/2017/03/Dynamic-Provisioning-And-Storage-Classes-Kubernetes"> Dynamic Provisioning and Storage Classes in Kubernetes </a></li>
      
        
              
        
    

    
    
    
    
    
        <li><a href="/blog/2017/03/Kubernetes-1.6-Multi-User-Multi-Workloads-At-Scale"> Kubernetes 1.6: Multi-user, Multi-workloads at Scale </a></li>
      
        
              
        
    

    
    
    
    
    
        <li><a href="/blog/2017/03/K8Sport-Engaging-The-Kubernetes-Community"> The K8sPort: Engaging Kubernetes Community One Activity at a Time </a></li>
      
        
              
              </ul>


              <input type="checkbox" id="2017-February-ref-checkbox" class="heading-month-toggle-checkbox"/>
              <label class="collapsible-month-heading-label" for="2017-February-ref-checkbox">
                <span class="collapsible-posts-list-caret">►&nbsp;</span>
                <h5 class="collapsible-month-header" id="2017-February-ref">February</h5>
              </label>

              <ul class="collapsible-posts-list">
            
        
    

    
    
    
    
    
        <li><a href="/blog/2017/02/Postgresql-Clusters-Kubernetes-Statefulsets"> Deploying PostgreSQL Clusters using StatefulSets </a></li>
      
        
              
        
    

    
    
    
    
    
        <li><a href="/blog/2017/02/Caas-The-Foundation-For-Next-Gen-Paas"> Containers as a Service, the foundation for next generation PaaS </a></li>
      
        
              
        
    

    
    
    
    
    
        <li><a href="/blog/2017/02/Inside-Jd-Com-Shift-To-Kubernetes-From-Openstack"> Inside JD.com's Shift to Kubernetes from OpenStack </a></li>
      
        
              
        
    

    
    
    
    
    
        <li><a href="/blog/2017/02/Run-Deep-Learning-With-Paddlepaddle-On-Kubernetes"> Run Deep Learning with PaddlePaddle on Kubernetes </a></li>
      
        
              
        
    

    
    
    
    
    
        <li><a href="/blog/2017/02/Highly-Available-Kubernetes-Clusters"> Highly Available Kubernetes Clusters </a></li>
      
        
              
              </ul>


              <input type="checkbox" id="2017-January-ref-checkbox" class="heading-month-toggle-checkbox"/>
              <label class="collapsible-month-heading-label" for="2017-January-ref-checkbox">
                <span class="collapsible-posts-list-caret">►&nbsp;</span>
                <h5 class="collapsible-month-header" id="2017-January-ref">January</h5>
              </label>

              <ul class="collapsible-posts-list">
            
        
    

    
    
    
    
    
        <li><a href="/blog/2017/01/Running-Mongodb-On-Kubernetes-With-Statefulsets"> Running MongoDB on Kubernetes with StatefulSets </a></li>
      
        
              
        
    

    
    
    
    
    
        <li><a href="/blog/2017/01/Fission-Serverless-Functions-As-Service-For-Kubernetes"> Fission: Serverless Functions as a Service for Kubernetes </a></li>
      
        
              
        
    

    
    
    
    
    
        <li><a href="/blog/2017/01/How-We-Run-Kubernetes-In-Kubernetes-Kubeception"> How we run Kubernetes in Kubernetes aka Kubeception </a></li>
      
        
              
        
    

    
    
    
    
    
        <li><a href="/blog/2017/01/Scaling-Kubernetes-Deployments-With-Policy-Base-Networking"> Scaling Kubernetes deployments with Policy-Based Networking </a></li>
      
        
              
        
    

    
    
    
    
    
        <li><a href="/blog/2017/01/Stronger-Foundation-For-Creating-And-Managing-Kubernetes-Clusters"> A Stronger Foundation for Creating and Managing Kubernetes Clusters </a></li>
      
        
              
        
    

    
    
    
    
    
        <li><a href="/blog/2017/01/Kubernetes-Ux-Survey-Infographic"> Kubernetes UX Survey Infographic </a></li>
      
        
          </ul>
          <!-- this closes the collapsible year body -->
        </div>
        <!-- this closes the sidebar-previous-year opened below -->
      </div>
      <div class="sidebar-previous-year">
        <input type="checkbox" id="2016-ref-checkbox" class="heading-year-toggle-checkbox"/>
        <label class="collapsible-year-heading-label" for="2016-ref-checkbox">
          <span class="collapsible-year-body-caret">►&nbsp;</span>
          <h4 class="collapsible-year-header" id="2016-ref">2016</h4>
        </label>
        <div class="collapsible-year-body">
          <input type="checkbox" id="2016-December-ref-checkbox" class="heading-month-toggle-checkbox"/>
          <label class="collapsible-month-heading-label" for="2016-December-ref-checkbox">
            <span class="collapsible-posts-list-caret">►&nbsp;</span>
            <h5 class="collapsible-month-header" id="2016-December-ref">December</h5>
          </label>
          <ul class="collapsible-posts-list">
            
    

    
    
    
    
    
        <li><a href="/blog/2016/12/Kubernetes-Supports-Openapi"> Kubernetes supports OpenAPI </a></li>
      
        
              
        
    

    
    
    
    
    
        <li><a href="/blog/2016/12/Cluster-Federation-In-Kubernetes-1.5"> Cluster Federation in Kubernetes 1.5 </a></li>
      
        
              
        
    

    
    
    
    
    
        <li><a href="/blog/2016/12/Windows-Server-Support-Kubernetes"> Windows Server Support Comes to Kubernetes </a></li>
      
        
              
        
    

    
    
    
    
    
        <li><a href="/blog/2016/12/Statefulset-Run-Scale-Stateful-Applications-In-Kubernetes"> StatefulSet: Run and Scale Stateful Applications Easily in Kubernetes </a></li>
      
        
              
        
    

    
    
    
    
    
        <li><a href="/blog/2016/12/Five-Days-Of-Kubernetes-1.5"> Five Days of Kubernetes 1.5 </a></li>
      
        
              
        
    

    
    
    
    
    
        <li><a href="/blog/2016/12/Container-Runtime-Interface-Cri-In-Kubernetes"> Introducing Container Runtime Interface (CRI) in Kubernetes </a></li>
      
        
              
        
    

    
    
    
    
    
        <li><a href="/blog/2016/12/Kubernetes-1.5-Supporting-Production-Workloads"> Kubernetes 1.5: Supporting Production Workloads </a></li>
      
        
              
        
    

    
    
    
    
    
        <li><a href="/blog/2016/12/From-Network-Policies-To-Security-Policies"> From Network Policies to Security Policies </a></li>
      
        
              
              </ul>


              <input type="checkbox" id="2016-November-ref-checkbox" class="heading-month-toggle-checkbox"/>
              <label class="collapsible-month-heading-label" for="2016-November-ref-checkbox">
                <span class="collapsible-posts-list-caret">►&nbsp;</span>
                <h5 class="collapsible-month-header" id="2016-November-ref">November</h5>
              </label>

              <ul class="collapsible-posts-list">
            
        
    

    
    
    
    
    
        <li><a href="/blog/2016/11/Kompose-Tool-Go-From-Docker-Compose-To-Kubernetes"> Kompose: a tool to go from Docker-compose to Kubernetes </a></li>
      
        
              
        
    

    
    
    
    
    
        <li><a href="/blog/2016/11/Kubernetes-Containers-Logging-Monitoring-With-Sematext"> Kubernetes Containers Logging and Monitoring with Sematext </a></li>
      
        
              
        
    

    
    
    
    
    
        <li><a href="/blog/2016/11/Visualize-Kubelet-Performance-With-Node-Dashboard"> Visualize Kubelet Performance with Node Dashboard </a></li>
      
        
              
        
    

    
    
    
    
    
        <li><a href="/blog/2016/11/Kubernetes-Certification-Training-And-Managed-Service-Provider-Program"> CNCF Partners With The Linux Foundation To Launch New Kubernetes Certification, Training and Managed Service Provider Program </a></li>
      
        
              
        
    

    
    
    
    
    
        <li><a href="/blog/2016/11/Skytap-Modernizing-Microservice-Architecture-With-Kubernetes"> Modernizing the Skytap Cloud Micro-Service Architecture with Kubernetes </a></li>
      
        
              
        
    

    
    
    
    
    
        <li><a href="/blog/2016/11/Bringing-Kubernetes-Support-To-Azure"> Bringing Kubernetes Support to Azure Container Service </a></li>
      
        
              
              </ul>


              <input type="checkbox" id="2016-October-ref-checkbox" class="heading-month-toggle-checkbox"/>
              <label class="collapsible-month-heading-label" for="2016-October-ref-checkbox">
                <span class="collapsible-posts-list-caret">►&nbsp;</span>
                <h5 class="collapsible-month-header" id="2016-October-ref">October</h5>
              </label>

              <ul class="collapsible-posts-list">
            
        
    

    
    
    
    
    
        <li><a href="/blog/2016/10/Tail-Kubernetes-With-Stern"> Tail Kubernetes with Stern </a></li>
      
        
              
        
    

    
    
    
    
    
        <li><a href="/blog/2016/10/Kubernetes-Service-Technology-Partners-Program"> Introducing Kubernetes Service Partners program and a redesigned Partners page </a></li>
      
        
              
        
    

    
    
    
    
    
        <li><a href="/blog/2016/10/Kubernetes-And-Openstack-At-Yahoo-Japan">  How We Architected and Run Kubernetes on OpenStack at Scale at Yahoo! JAPAN </a></li>
      
        
              
        
    

    
    
    
    
    
        <li><a href="/blog/2016/10/Globally-Distributed-Services-Kubernetes-Cluster-Federation"> Building Globally Distributed Services using Kubernetes Cluster Federation </a></li>
      
        
              
        
    

    
    
    
    
    
        <li><a href="/blog/2016/10/Helm-Charts-Making-It-Simple-To-Package-And-Deploy-Apps-On-Kubernetes"> Helm Charts: making it simple to package and deploy common applications on Kubernetes </a></li>
      
        
              
        
    

    
    
    
    
    
        <li><a href="/blog/2016/10/Dynamic-Provisioning-And-Storage-In-Kubernetes"> Dynamic Provisioning and Storage Classes in Kubernetes </a></li>
      
        
              
        
    

    
    
    
    
    
        <li><a href="/blog/2016/10/Production-Kubernetes-Dashboard-UI-1.4-improvements_3"> How we improved Kubernetes Dashboard UI in 1.4 for your production needs​ </a></li>
      
        
              
              </ul>


              <input type="checkbox" id="2016-September-ref-checkbox" class="heading-month-toggle-checkbox"/>
              <label class="collapsible-month-heading-label" for="2016-September-ref-checkbox">
                <span class="collapsible-posts-list-caret">►&nbsp;</span>
                <h5 class="collapsible-month-header" id="2016-September-ref">September</h5>
              </label>

              <ul class="collapsible-posts-list">
            
        
    

    
    
    
    
    
        <li><a href="/blog/2016/09/How-We-Made-Kubernetes-Easy-To-Install"> How we made Kubernetes insanely easy to install </a></li>
      
        
              
        
    

    
    
    
    
    
        <li><a href="/blog/2016/09/How-Qbox-Saved-50-Percent-On-Aws-Bills"> How Qbox Saved 50% per Month on AWS Bills Using Kubernetes and Supergiant </a></li>
      
        
              
        
    

    
    
    
    
    
        <li><a href="/blog/2016/09/Kubernetes-1.4-Making-It-Easy-To-Run-On-Kuberentes-Anywhere"> Kubernetes 1.4: Making it easy to run on Kubernetes anywhere </a></li>
      
        
              
        
    

    
    
    
    
    
        <li><a href="/blog/2016/09/High-Performance-Network-Policies-Kubernetes"> High performance network policies in Kubernetes clusters </a></li>
      
        
              
        
    

    
    
    
    
    
        <li><a href="/blog/2016/09/Creating-Postgresql-Cluster-Using-Helm"> Creating a PostgreSQL Cluster using Helm </a></li>
      
        
              
        
    

    
    
    
    
    
        <li><a href="/blog/2016/09/Deploying-To-Multiple-Kubernetes-With-Kit"> Deploying to Multiple Kubernetes Clusters with kit </a></li>
      
        
              
        
    

    
    
    
    
    
        <li><a href="/blog/2016/09/Cloud-Native-Application-Interfaces"> Cloud Native Application Interfaces </a></li>
      
        
              
              </ul>


              <input type="checkbox" id="2016-August-ref-checkbox" class="heading-month-toggle-checkbox"/>
              <label class="collapsible-month-heading-label" for="2016-August-ref-checkbox">
                <span class="collapsible-posts-list-caret">►&nbsp;</span>
                <h5 class="collapsible-month-header" id="2016-August-ref">August</h5>
              </label>

              <ul class="collapsible-posts-list">
            
        
    

    
    
    
    
    
        <li><a href="/blog/2016/08/Security-Best-Practices-Kubernetes-Deployment"> Security Best Practices for Kubernetes Deployment </a></li>
      
        
              
        
    

    
    
    
    
    
        <li><a href="/blog/2016/08/Stateful-Applications-Using-Kubernetes-Datera"> Scaling Stateful Applications using Kubernetes Pet Sets and FlexVolumes with Datera Elastic Data Fabric </a></li>
      
        
              
        
    

    
    
    
    
    
        <li><a href="/blog/2016/08/Sig-Apps-Running-Apps-In-Kubernetes"> SIG Apps: build apps for and operate them in Kubernetes </a></li>
      
        
              
        
    

    
    
    
    
    
        <li><a href="/blog/2016/08/Kubernetes-Namespaces-Use-Cases-Insights"> Kubernetes Namespaces: use cases and insights </a></li>
      
        
              
        
    

    
    
    
    
    
        <li><a href="/blog/2016/08/Create-Couchbase-Cluster-Using-Kubernetes"> Create a Couchbase cluster using Kubernetes </a></li>
      
        
              
        
    

    
    
    
    
    
        <li><a href="/blog/2016/08/Challenges-Remotely-Managed-Onpremise-Kubernetes-Cluster"> Challenges of a Remotely Managed, On-Premises, Bare-Metal Kubernetes Cluster </a></li>
      
        
              
              </ul>


              <input type="checkbox" id="2016-July-ref-checkbox" class="heading-month-toggle-checkbox"/>
              <label class="collapsible-month-heading-label" for="2016-July-ref-checkbox">
                <span class="collapsible-posts-list-caret">►&nbsp;</span>
                <h5 class="collapsible-month-header" id="2016-July-ref">July</h5>
              </label>

              <ul class="collapsible-posts-list">
            
        
    

    
    
    
    
    
        <li><a href="/blog/2016/07/openstack-kubernetes-communities"> Why OpenStack's embrace of Kubernetes is great for both communities </a></li>
      
        
              
        
    

    
    
    
    
    
        <li><a href="/blog/2016/07/happy-k8sbday-1"> A Very Happy Birthday Kubernetes </a></li>
      
        
              
        
    

    
    
    
    
    
        <li><a href="/blog/2016/07/The-Bet-On-Kubernetes"> The Bet on Kubernetes, a Red Hat Perspective </a></li>
      
        
              
        
    

    
    
    
    
    
        <li><a href="/blog/2016/07/Oh-The-Places-You-Will-Go"> Happy Birthday Kubernetes. Oh, the places you’ll go! </a></li>
      
        
              
        
    

    
    
    
    
    
        <li><a href="/blog/2016/07/Bringing-End-To-End-Kubernetes-Testing-To-Azure-2"> Bringing End-to-End Kubernetes Testing to Azure (Part 2) </a></li>
      
        
              
        
    

    
    
    
    
    
        <li><a href="/blog/2016/07/Dashboard-Web-Interface-For-Kubernetes"> Dashboard - Full Featured Web Interface for Kubernetes </a></li>
      
        
              
        
    

    
    
    
    
    
        <li><a href="/blog/2016/07/Automation-Platform-At-Wercker-With-Kubernetes"> Steering an Automation Platform at Wercker with Kubernetes </a></li>
      
        
              
        
    

    
    
    
    
    
        <li><a href="/blog/2016/07/Cross-Cluster-Services"> Cross Cluster Services - Achieving Higher Availability for your Kubernetes Applications </a></li>
      
        
              
        
    

    
    
    
    
    
        <li><a href="/blog/2016/07/Citrix-Netscaler-And-Kubernetes"> Citrix + Kubernetes = A Home Run </a></li>
      
        
              
        
    

    
    
    
    
    
        <li><a href="/blog/2016/07/stateful-applications-in-containers-kubernetes"> Stateful Applications in Containers!? Kubernetes 1.3 Says “Yes!” </a></li>
      
        
              
        
    

    
    
    
    
    
        <li><a href="/blog/2016/07/Thousand-Instances-Of-Cassandra-Using-Kubernetes-Pet-Set"> Thousand Instances of Cassandra using Kubernetes Pet Set </a></li>
      
        
              
        
    

    
    
    
    
    
        <li><a href="/blog/2016/07/Kubernetes-In-Rancher-Further-Evolution"> Kubernetes in Rancher: the further evolution </a></li>
      
        
              
        
    

    
    
    
    
    
        <li><a href="/blog/2016/07/Autoscaling-In-Kubernetes"> Autoscaling in Kubernetes </a></li>
      
        
              
        
    

    
    
    
    
    
        <li><a href="/blog/2016/07/Rktnetes-Brings-Rkt-Container-Engine-To-Kubernetes"> rktnetes brings rkt container engine to Kubernetes </a></li>
      
        
              
        
    

    
    
    
    
    
        <li><a href="/blog/2016/07/Minikube-Easily-Run-Kubernetes-Locally"> Minikube: easily run Kubernetes locally  </a></li>
      
        
              
        
    

    
    
    
    
    
        <li><a href="/blog/2016/07/Five-Days-Of-Kubernetes-1.3"> Five Days of Kubernetes 1.3 </a></li>
      
        
              
        
    

    
    
    
    
    
        <li><a href="/blog/2016/07/Update-On-Kubernetes-For-Windows-Server-Containers"> Updates to Performance and Scalability in Kubernetes 1.3 -- 2,000 node 60,000 pod clusters </a></li>
      
        
              
        
    

    
    
    
    
    
        <li><a href="/blog/2016/07/Kubernetes-1.3-Bridging-Cloud-Native-And-Enterprise-Workloads"> Kubernetes 1.3: Bridging Cloud Native and Enterprise Workloads </a></li>
      
        
              
              </ul>


              <input type="checkbox" id="2016-June-ref-checkbox" class="heading-month-toggle-checkbox"/>
              <label class="collapsible-month-heading-label" for="2016-June-ref-checkbox">
                <span class="collapsible-posts-list-caret">►&nbsp;</span>
                <h5 class="collapsible-month-header" id="2016-June-ref">June</h5>
              </label>

              <ul class="collapsible-posts-list">
            
        
    

    
    
    
    
    
        <li><a href="/blog/2016/06/Container-Design-Patterns"> Container Design Patterns </a></li>
      
        
              
        
    

    
    
    
    
    
        <li><a href="/blog/2016/06/Illustrated-Childrens-Guide-To-Kubernetes"> The Illustrated Children's Guide to Kubernetes </a></li>
      
        
              
        
    

    
    
    
    
    
        <li><a href="/blog/2016/06/Bringing-End-To-End-Testing-To-Azure"> Bringing End-to-End Kubernetes Testing to Azure (Part 1) </a></li>
      
        
              
              </ul>


              <input type="checkbox" id="2016-May-ref-checkbox" class="heading-month-toggle-checkbox"/>
              <label class="collapsible-month-heading-label" for="2016-May-ref-checkbox">
                <span class="collapsible-posts-list-caret">►&nbsp;</span>
                <h5 class="collapsible-month-header" id="2016-May-ref">May</h5>
              </label>

              <ul class="collapsible-posts-list">
            
        
    

    
    
    
    
    
        <li><a href="/blog/2016/05/Hypernetes-Security-And-Multi-Tenancy-In-Kubernetes"> Hypernetes: Bringing Security and Multi-tenancy to Kubernetes </a></li>
      
        
              
        
    

    
    
    
    
    
        <li><a href="/blog/2016/05/Coreosfest2016-Kubernetes-Community"> CoreOS Fest 2016: CoreOS and Kubernetes Community meet in Berlin (& San Francisco) </a></li>
      
        
              
              </ul>


              <input type="checkbox" id="2016-April-ref-checkbox" class="heading-month-toggle-checkbox"/>
              <label class="collapsible-month-heading-label" for="2016-April-ref-checkbox">
                <span class="collapsible-posts-list-caret">►&nbsp;</span>
                <h5 class="collapsible-month-header" id="2016-April-ref">April</h5>
              </label>

              <ul class="collapsible-posts-list">
            
        
    

    
    
    
    
    
        <li><a href="/blog/2016/04/Introducing-Kubernetes-Openstack-Sig"> Introducing the Kubernetes OpenStack Special Interest Group </a></li>
      
        
              
        
    

    
    
    
    
    
        <li><a href="/blog/2016/04/Building-Awesome-User-Interfaces-For-Kubernetes"> SIG-UI: the place for building awesome user interfaces for Kubernetes </a></li>
      
        
              
        
    

    
    
    
    
    
        <li><a href="/blog/2016/04/Sig-Clusterops-Promote-Operability-And-Interoperability-Of-K8S-Clusters"> SIG-ClusterOps: Promote operability and interoperability of Kubernetes clusters </a></li>
      
        
              
        
    

    
    
    
    
    
        <li><a href="/blog/2016/04/Kubernetes-Network-Policy-APIs"> SIG-Networking: Kubernetes Network Policy APIs Coming in 1.3 </a></li>
      
        
              
        
    

    
    
    
    
    
        <li><a href="/blog/2016/04/Kubernetes-On-Aws_15"> How to deploy secure, auditable, and reproducible Kubernetes clusters on AWS </a></li>
      
        
              
        
    

    
    
    
    
    
        <li><a href="/blog/2016/04/Container-Survey-Results-March-2016"> Container survey results - March 2016 </a></li>
      
        
              
        
    

    
    
    
    
    
        <li><a href="/blog/2016/04/Adding-Support-For-Kubernetes-In-Rancher"> Adding Support for Kubernetes in Rancher </a></li>
      
        
              
        
    

    
    
    
    
    
        <li><a href="/blog/2016/04/Configuration-Management-With-Containers"> Configuration management with Containers </a></li>
      
        
              
        
    

    
    
    
    
    
        <li><a href="/blog/2016/04/Using-Deployment-Objects-With"> Using Deployment objects with Kubernetes 1.2 </a></li>
      
        
              
              </ul>


              <input type="checkbox" id="2016-March-ref-checkbox" class="heading-month-toggle-checkbox"/>
              <label class="collapsible-month-heading-label" for="2016-March-ref-checkbox">
                <span class="collapsible-posts-list-caret">►&nbsp;</span>
                <h5 class="collapsible-month-header" id="2016-March-ref">March</h5>
              </label>

              <ul class="collapsible-posts-list">
            
        
    

    
    
    
    
    
        <li><a href="/blog/2016/03/Kubernetes-1.2-And-Simplifying-Advanced-Networking-With-Ingress"> Kubernetes 1.2 and simplifying advanced networking with Ingress </a></li>
      
        
              
        
    

    
    
    
    
    
        <li><a href="/blog/2016/03/Using-Spark-And-Zeppelin-To-Process-Big-Data-On-Kubernetes"> Using Spark and Zeppelin to process big data on Kubernetes 1.2 </a></li>
      
        
              
        
    

    
    
    
    
    
        <li><a href="/blog/2016/03/Building-Highly-Available-Applications-Using-Kubernetes-New-Multi-Zone-Clusters-A.K.A-Ubernetes-Lite"> Building highly available applications using Kubernetes new multi-zone clusters (a.k.a. 'Ubernetes Lite') </a></li>
      
        
              
        
    

    
    
    
    
    
        <li><a href="/blog/2016/03/Appformix-Helping-Enterprises"> AppFormix: Helping Enterprises Operationalize Kubernetes </a></li>
      
        
              
        
    

    
    
    
    
    
        <li><a href="/blog/2016/03/How-Container-Metadata-Changes-Your-Point-Of-View"> How container metadata changes your point of view </a></li>
      
        
              
        
    

    
    
    
    
    
        <li><a href="/blog/2016/03/Five-Days-Of-Kubernetes-12"> Five Days of Kubernetes 1.2 </a></li>
      
        
              
        
    

    
    
    
    
    
        <li><a href="/blog/2016/03/1000-Nodes-And-Beyond-Updates-To-Kubernetes-Performance-And-Scalability-In-12"> 1000 nodes and beyond: updates to Kubernetes performance and scalability in 1.2 </a></li>
      
        
              
        
    

    
    
    
    
    
        <li><a href="/blog/2016/03/Scaling-Neural-Network-Image-Classification-Using-Kubernetes-With-Tensorflow-Serving"> Scaling neural network image classification using Kubernetes with TensorFlow Serving  </a></li>
      
        
              
        
    

    
    
    
    
    
        <li><a href="/blog/2016/03/Kubernetes-1.2-Even-More-Performance-Upgrades-Plus-Easier-Application-Deployment-And-Management"> Kubernetes 1.2: Even more performance upgrades, plus easier application deployment and management  </a></li>
      
        
              
        
    

    
    
    
    
    
        <li><a href="/blog/2016/03/Kubernetes-In-Enterprise-With-Fujitsus"> Kubernetes in the Enterprise with Fujitsu’s Cloud Load Control </a></li>
      
        
              
        
    

    
    
    
    
    
        <li><a href="/blog/2016/03/Elasticbox-Introduces-Elastickube-To"> ElasticBox introduces ElasticKube to help manage Kubernetes within the enterprise </a></li>
      
        
              
        
    

    
    
    
    
    
        <li><a href="/blog/2016/03/State-Of-Container-World-February-2016"> State of the Container World, February 2016 </a></li>
      
        
              
        
    

    
    
    
    
    
        <li><a href="/blog/2016/03/Kubernetes-Community-Meeting-Notes"> Kubernetes Community Meeting Notes - 20160225 </a></li>
      
        
              
              </ul>


              <input type="checkbox" id="2016-February-ref-checkbox" class="heading-month-toggle-checkbox"/>
              <label class="collapsible-month-heading-label" for="2016-February-ref-checkbox">
                <span class="collapsible-posts-list-caret">►&nbsp;</span>
                <h5 class="collapsible-month-header" id="2016-February-ref">February</h5>
              </label>

              <ul class="collapsible-posts-list">
            
        
    

    
    
    
    
    
        <li><a href="/blog/2016/02/Kubecon-Eu-2016-Kubernetes-Community-In"> KubeCon EU 2016: Kubernetes Community in London </a></li>
      
        
              
        
    

    
    
    
    
    
        <li><a href="/blog/2016/02/kubernetes-community-meeting-notes_23"> Kubernetes Community Meeting Notes - 20160218 </a></li>
      
        
              
        
    

    
    
    
    
    
        <li><a href="/blog/2016/02/Kubernetes-community-meeting-notes-20160211"> Kubernetes Community Meeting Notes - 20160211 </a></li>
      
        
              
        
    

    
    
    
    
    
        <li><a href="/blog/2016/02/Sharethis-Kubernetes-In-Production"> ShareThis: Kubernetes In Production </a></li>
      
        
              
        
    

    
    
    
    
    
        <li><a href="/blog/2016/02/Kubernetes-Community-Meeting-Notes"> Kubernetes Community Meeting Notes - 20160204 </a></li>
      
        
              
        
    

    
    
    
    
    
        <li><a href="/blog/2016/02/Kubernetes-community-meeting-notes-20160128"> Kubernetes Community Meeting Notes - 20160128 </a></li>
      
        
              
        
    

    
    
    
    
    
        <li><a href="/blog/2016/02/State-Of-Container-World-January-2016"> State of the Container World, January 2016 </a></li>
      
        
              
              </ul>


              <input type="checkbox" id="2016-January-ref-checkbox" class="heading-month-toggle-checkbox"/>
              <label class="collapsible-month-heading-label" for="2016-January-ref-checkbox">
                <span class="collapsible-posts-list-caret">►&nbsp;</span>
                <h5 class="collapsible-month-header" id="2016-January-ref">January</h5>
              </label>

              <ul class="collapsible-posts-list">
            
        
    

    
    
    
    
    
        <li><a href="/blog/2016/01/Kubernetes-Community-Meeting-Notes_28">Kubernetes Community Meeting Notes - 20160121</a></li>
      
        
              
        
    

    
    
    
    
    
        <li><a href="/blog/2016/01/Kubernetes-Community-Meeting-Notes"> Kubernetes Community Meeting Notes - 20160114 </a></li>
      
        
              
        
    

    
    
    
    
    
        <li><a href="/blog/2016/01/Why-Kubernetes-Doesnt-Use-Libnetwork"> Why Kubernetes doesn’t use libnetwork </a></li>
      
        
              
        
    

    
    
    
    
    
        <li><a href="/blog/2016/01/Simple-Leader-Election-With-Kubernetes"> Simple leader election with Kubernetes and Docker </a></li>
      
        
          </ul>
          <!-- this closes the collapsible year body -->
        </div>
        <!-- this closes the sidebar-previous-year opened below -->
      </div>
      <div class="sidebar-previous-year">
        <input type="checkbox" id="2015-ref-checkbox" class="heading-year-toggle-checkbox"/>
        <label class="collapsible-year-heading-label" for="2015-ref-checkbox">
          <span class="collapsible-year-body-caret">►&nbsp;</span>
          <h4 class="collapsible-year-header" id="2015-ref">2015</h4>
        </label>
        <div class="collapsible-year-body">
          <input type="checkbox" id="2015-December-ref-checkbox" class="heading-month-toggle-checkbox"/>
          <label class="collapsible-month-heading-label" for="2015-December-ref-checkbox">
            <span class="collapsible-posts-list-caret">►&nbsp;</span>
            <h5 class="collapsible-month-header" id="2015-December-ref">December</h5>
          </label>
          <ul class="collapsible-posts-list">
            
    

    
    
    
    
    
        <li><a href="/blog/2015/12/Creating-Raspberry-Pi-Cluster-Running"> Creating a Raspberry Pi cluster running Kubernetes, the installation (Part 2) </a></li>
      
        
              
        
    

    
    
    
    
    
        <li><a href="/blog/2015/12/Managing-Kubernetes-Pods-Services-And-Replication-Controllers-With-Puppet"> Managing Kubernetes Pods, Services and Replication Controllers with Puppet </a></li>
      
        
              
        
    

    
    
    
    
    
        <li><a href="/blog/2015/12/How-Weave-Built-A-Multi-Deployment-Solution-For-Scope-Using-Kubernetes"> How Weave built a multi-deployment solution for Scope using Kubernetes </a></li>
      
        
              
              </ul>


              <input type="checkbox" id="2015-November-ref-checkbox" class="heading-month-toggle-checkbox"/>
              <label class="collapsible-month-heading-label" for="2015-November-ref-checkbox">
                <span class="collapsible-posts-list-caret">►&nbsp;</span>
                <h5 class="collapsible-month-header" id="2015-November-ref">November</h5>
              </label>

              <ul class="collapsible-posts-list">
            
        
    

    
    
    
    
    
        <li><a href="/blog/2015/11/Creating-A-Raspberry-Pi-Cluster-Running-Kubernetes-The-Shopping-List-Part-1"> Creating a Raspberry Pi cluster running Kubernetes, the shopping list (Part 1) </a></li>
      
        
              
        
    

    
    
    
    
    
        <li><a href="/blog/2015/11/Monitoring-Kubernetes-With-Sysdig"> Monitoring Kubernetes with Sysdig </a></li>
      
        
              
        
    

    
    
    
    
    
        <li><a href="/blog/2015/11/One-Million-Requests-Per-Second-Dependable-And-Dynamic-Distributed-Systems-At-Scale"> One million requests per second: Dependable and dynamic distributed systems at scale </a></li>
      
        
              
        
    

    
    
    
    
    
        <li><a href="/blog/2015/11/Kubernetes-1-1-Performance-Upgrades-Improved-Tooling-And-A-Growing-Community"> Kubernetes 1.1 Performance upgrades, improved tooling and a growing community  </a></li>
      
        
              
        
    

    
    
    
    
    
        <li><a href="/blog/2015/11/Kubernetes-As-Foundation-For-Cloud-Native-Paas"> Kubernetes as Foundation for Cloud Native PaaS </a></li>
      
        
              
              </ul>


              <input type="checkbox" id="2015-October-ref-checkbox" class="heading-month-toggle-checkbox"/>
              <label class="collapsible-month-heading-label" for="2015-October-ref-checkbox">
                <span class="collapsible-posts-list-caret">►&nbsp;</span>
                <h5 class="collapsible-month-header" id="2015-October-ref">October</h5>
              </label>

              <ul class="collapsible-posts-list">
            
        
    

    
    
    
    
    
        <li><a href="/blog/2015/10/Some-Things-You-Didnt-Know-About-Kubectl_28"> Some things you didn’t know about kubectl </a></li>
      
        
              
              </ul>


              <input type="checkbox" id="2015-September-ref-checkbox" class="heading-month-toggle-checkbox"/>
              <label class="collapsible-month-heading-label" for="2015-September-ref-checkbox">
                <span class="collapsible-posts-list-caret">►&nbsp;</span>
                <h5 class="collapsible-month-header" id="2015-September-ref">September</h5>
              </label>

              <ul class="collapsible-posts-list">
            
        
    

    
    
    
    
    
        <li><a href="/blog/2015/09/Kubernetes-Performance-Measurements-And"> Kubernetes Performance Measurements and Roadmap </a></li>
      
        
              
              </ul>


              <input type="checkbox" id="2015-August-ref-checkbox" class="heading-month-toggle-checkbox"/>
              <label class="collapsible-month-heading-label" for="2015-August-ref-checkbox">
                <span class="collapsible-posts-list-caret">►&nbsp;</span>
                <h5 class="collapsible-month-header" id="2015-August-ref">August</h5>
              </label>

              <ul class="collapsible-posts-list">
            
        
    

    
    
    
    
    
        <li><a href="/blog/2015/08/Using-Kubernetes-Namespaces-To-Manage"> Using Kubernetes Namespaces to Manage Environments </a></li>
      
        
              
        
    

    
    
    
    
    
        <li><a href="/blog/2015/08/Weekly-Kubernetes-Community-Hangout"> Weekly Kubernetes Community Hangout Notes - July 31 2015 </a></li>
      
        
              
              </ul>


              <input type="checkbox" id="2015-July-ref-checkbox" class="heading-month-toggle-checkbox"/>
              <label class="collapsible-month-heading-label" for="2015-July-ref-checkbox">
                <span class="collapsible-posts-list-caret">►&nbsp;</span>
                <h5 class="collapsible-month-header" id="2015-July-ref">July</h5>
              </label>

              <ul class="collapsible-posts-list">
            
        
    

    
    
    
    
    
        <li><a href="/blog/2015/07/The-Growing-Kubernetes-Ecosystem"> The Growing Kubernetes Ecosystem </a></li>
      
        
              
        
    

    
    
    
    
    
        <li><a href="/blog/2015/07/Weekly-Kubernetes-Community-Hangout_23"> Weekly Kubernetes Community Hangout Notes - July 17 2015 </a></li>
      
        
              
        
    

    
    
    
    
    
        <li><a href="/blog/2015/07/Strong-Simple-Ssl-For-Kubernetes"> Strong, Simple SSL for Kubernetes Services </a></li>
      
        
              
        
    

    
    
    
    
    
        <li><a href="/blog/2015/07/Weekly-Kubernetes-Community-Hangout"> Weekly Kubernetes Community Hangout Notes - July 10 2015 </a></li>
      
        
              
        
    

    
    
    
    
    
        <li><a href="/blog/2015/07/Announcing-First-Kubernetes-Enterprise"> Announcing the First Kubernetes Enterprise Training Course </a></li>
      
        
              
        
    

    
    
    
    
    
        <li><a href="/blog/2015/07/Kubernetes-10-Launch-Party-At-Oscon"> Kubernetes 1.0 Launch Event at OSCON </a></li>
      
        
              
        
    

    
    
    
    
    
        <li><a href="/blog/2015/07/How-Did-Quake-Demo-From-Dockercon-Work"> How did the Quake demo from DockerCon Work? </a></li>
      
        
              
              </ul>


              <input type="checkbox" id="2015-June-ref-checkbox" class="heading-month-toggle-checkbox"/>
              <label class="collapsible-month-heading-label" for="2015-June-ref-checkbox">
                <span class="collapsible-posts-list-caret">►&nbsp;</span>
                <h5 class="collapsible-month-header" id="2015-June-ref">June</h5>
              </label>

              <ul class="collapsible-posts-list">
            
        
    

    
    
    
    
    
        <li><a href="/blog/2015/06/The-Distributed-System-Toolkit-Patterns"> The Distributed System ToolKit: Patterns for Composite Containers </a></li>
      
        
              
        
    

    
    
    
    
    
        <li><a href="/blog/2015/06/Slides-Cluster-Management-With"> Slides: Cluster Management with Kubernetes, talk given at the University of Edinburgh </a></li>
      
        
              
        
    

    
    
    
    
    
        <li><a href="/blog/2015/06/Cluster-Level-Logging-With-Kubernetes"> Cluster Level Logging with Kubernetes </a></li>
      
        
              
        
    

    
    
    
    
    
        <li><a href="/blog/2015/06/Weekly-Kubernetes-Community-Hangout"> Weekly Kubernetes Community Hangout Notes - May 22 2015 </a></li>
      
        
              
              </ul>


              <input type="checkbox" id="2015-May-ref-checkbox" class="heading-month-toggle-checkbox"/>
              <label class="collapsible-month-heading-label" for="2015-May-ref-checkbox">
                <span class="collapsible-posts-list-caret">►&nbsp;</span>
                <h5 class="collapsible-month-header" id="2015-May-ref">May</h5>
              </label>

              <ul class="collapsible-posts-list">
            
        
    

    
    
    
    
    
        <li><a href="/blog/2015/05/Kubernetes-On-Openstack"> Kubernetes on OpenStack </a></li>
      
        
              
        
    

    
    
    
    
    
        <li><a href="/blog/2015/05/Weekly-Kubernetes-Community-Hangout_18"> Weekly Kubernetes Community Hangout Notes - May 15 2015 </a></li>
      
        
              
        
    

    
    
    
    
    
        <li><a href="/blog/2015/05/Docker-And-Kubernetes-And-Appc"> Docker and Kubernetes and AppC  </a></li>
      
        
              
        
    

    
    
    
    
    
        <li><a href="/blog/2015/05/Kubernetes-Release-0170"> Kubernetes Release: 0.17.0 </a></li>
      
        
              
        
    

    
    
    
    
    
        <li><a href="/blog/2015/05/Resource-Usage-Monitoring-Kubernetes">Resource Usage Monitoring in Kubernetes</a></li>
      
        
              
        
    

    
    
    
    
    
        <li><a href="/blog/2015/05/Weekly-Kubernetes-Community-Hangout"> Weekly Kubernetes Community Hangout Notes - May 1 2015 </a></li>
      
        
              
        
    

    
    
    
    
    
        <li><a href="/blog/2015/05/Kubernetes-Release-0160"> Kubernetes Release: 0.16.0 </a></li>
      
        
              
        
    

    
    
    
    
    
        <li><a href="/blog/2015/05/Appc-Support-For-Kubernetes-Through-Rkt"> AppC Support for Kubernetes through RKT </a></li>
      
        
              
              </ul>


              <input type="checkbox" id="2015-April-ref-checkbox" class="heading-month-toggle-checkbox"/>
              <label class="collapsible-month-heading-label" for="2015-April-ref-checkbox">
                <span class="collapsible-posts-list-caret">►&nbsp;</span>
                <h5 class="collapsible-month-header" id="2015-April-ref">April</h5>
              </label>

              <ul class="collapsible-posts-list">
            
        
    

    
    
    
    
    
        <li><a href="/blog/2015/04/Weekly-Kubernetes-Community-Hangout_29"> Weekly Kubernetes Community Hangout Notes - April 24 2015 </a></li>
      
        
              
        
    

    
    
    
    
    
        <li><a href="/blog/2015/04/Borg-Predecessor-To-Kubernetes"> Borg: The Predecessor to Kubernetes </a></li>
      
        
              
        
    

    
    
    
    
    
        <li><a href="/blog/2015/04/Kubernetes-And-Mesosphere-Dcos"> Kubernetes and the Mesosphere DCOS </a></li>
      
        
              
        
    

    
    
    
    
    
        <li><a href="/blog/2015/04/Weekly-Kubernetes-Community-Hangout_17"> Weekly Kubernetes Community Hangout Notes - April 17 2015 </a></li>
      
        
              
        
    

    
    
    
    
    
        <li><a href="/blog/2015/04/Kubernetes-Release-0150"> Kubernetes Release: 0.15.0 </a></li>
      
        
              
        
    

    
    
    
    
    
        <li><a href="/blog/2015/04/Introducing-Kubernetes-V1Beta3"> Introducing Kubernetes API Version v1beta3 </a></li>
      
        
              
        
    

    
    
    
    
    
        <li><a href="/blog/2015/04/Weekly-Kubernetes-Community-Hangout_11"> Weekly Kubernetes Community Hangout Notes - April 10 2015 </a></li>
      
        
              
        
    

    
    
    
    
    
        <li><a href="/blog/2015/04/Faster-Than-Speeding-Latte"> Faster than a speeding Latte </a></li>
      
        
              
        
    

    
    
    
    
    
        <li><a href="/blog/2015/04/Weekly-Kubernetes-Community-Hangout"> Weekly Kubernetes Community Hangout Notes - April 3 2015 </a></li>
      
        
              
              </ul>


              <input type="checkbox" id="2015-March-ref-checkbox" class="heading-month-toggle-checkbox"/>
              <label class="collapsible-month-heading-label" for="2015-March-ref-checkbox">
                <span class="collapsible-posts-list-caret">►&nbsp;</span>
                <h5 class="collapsible-month-header" id="2015-March-ref">March</h5>
              </label>

              <ul class="collapsible-posts-list">
            
        
    

    
    
    
    
    
        <li><a href="/blog/2015/03/Paricipate-In-Kubernetes-User"> Paricipate in a Kubernetes User Experience Study </a></li>
      
        
              
        
    

    
    
    
    
    
        <li><a href="/blog/2015/03/Weekly-Kubernetes-Community-Hangout"> Weekly Kubernetes Community Hangout Notes - March 27 2015 </a></li>
      
        
              
        
    

    
    
    
    
    
        <li><a href="/blog/2015/03/Kubernetes-Gathering-Videos"> Kubernetes Gathering Videos </a></li>
      
        
              
        
    

    
    
    
    
    
        <li><a href="/blog/2015/03/Welcome-To-Kubernetes-Blog">Welcome to the Kubernetes Blog!</a></li>
        <!-- This section closes the entire div and ul at the final iteration-->
      </ul>
    </div>
  </div>     <!-- end of final conditional -->
    


</div>


</div>

</div>
</body>
<footer col="12">
    <main class="light-text">
        <nav>
            <a href="/docs/tutorials/stateless-application/hello-minikube/">Get Started</a>
            <a href="/docs/home/">Documentation</a>
            <a href="/blog">Blog</a>
            <a href="/partners/">Partners</a>
            <a href="/community/">Community</a>
            <a href="/case-studies/">Case Studies</a>
        </nav>
        <div class="social">
            <div>
                <a href="https://twitter.com/kubernetesio" class="twitter"><span>twitter</span></a>
                <a href="https://github.com/kubernetes/kubernetes" class="github"><span>Github</span></a>
                <a href="http://slack.k8s.io/" class="slack"><span>Slack</span></a>
            </div>
            <div>
                <a href="http://stackoverflow.com/questions/tagged/kubernetes" class="stack-overflow"><span>Stack Overflow</span></a>
                <a href="https://groups.google.com/forum/#!forum/kubernetes-users" class="mailing-list"><span>Mailing List</span></a>
                <a href="https://calendar.google.com/calendar/embed?src=nt2tcnbtbied3l6gi2h29slvc0%40group.calendar.google.com" class="calendar"><span>Events Calendar</span></a>
            </div>
            <div>
                <a href="/docs/setup/pick-right-solution/" class="button">Get Kubernetes</a>
                <a href="https://github.com/kubernetes/kubernetes" class="button">Contribute</a>
            </div>
        </div>
        <div id="miceType" class="center">
            &copy; 2018 The Kubernetes Authors | Documentation Distributed under <a href="https://git.k8s.io/website/LICENSE" class="light-text">CC BY 4.0</a>
        </div>
        <div id="miceType" class="center">
            Copyright &copy; 2018 The Linux Foundation&reg;. All rights reserved. The Linux Foundation has registered trademarks and uses trademarks. For a list of trademarks of The Linux Foundation, please see our <a href="https://www.linuxfoundation.org/trademark-usage" class="light-text">Trademark Usage page</a>
        </div>
    </main>
</footer>

<button class="flyout-button" onclick="kub.toggleToc()"></button>

<style>
.cse .gsc-control-cse, .gsc-control-cse, {
    padding: 0;
}
  .gsc-control-cse table, .gsc-control-cse-en table {
      margin:0px !important;
  }
  .gsc-above-wrapper-area {
      border-bottom: 0;
  }
</style>

<script>
(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
    (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
})(window,document,'script','//www.google-analytics.com/analytics.js','ga');
ga('create', 'UA-36037335-10', 'auto');
ga('send', 'pageview');

// hide docs nav area if no nav is present, or if nav only contains a link to the current page
(function () {
    window.addEventListener('DOMContentLoaded', init)

        // play nice with our neighbors
        function init() {
            window.removeEventListener('DOMContentLoaded', init)
                hideNav()
        }

    function hideNav(toc){
        if (!toc) toc = document.querySelector('#docsToc')
        if (!toc) return
            var container = toc.querySelector('.container')

                // container is built dynamically, so it may not be present on the first runloop
                if (container) {
                    if (container.childElementCount === 0 || toc.querySelectorAll('a.item').length === 1) {
                        toc.style.display = 'none'
                            document.getElementById('docsContent').style.width = '100%'
                    }
                } else {
                    requestAnimationFrame(function () {
                        hideNav(toc)
                    })
                }
    }
})();
</script>

<!-- Commenting out AnswerDash for now; we need to work on our list of questions/answers/design first
    <!-- Start of AnswerDash script <script>var AnswerDash;!function(e,t,n,s,a){if(!t.getElementById(s)){var i,r=t.createElement(n),c=t.getElementsByTagName(n)[0];e[a]||(i=e[a]=function(){i.__oninit.push(arguments)},i.__oninit=[]),r.type="text/javascript",r.async=!0,r.src="https://p1.answerdash.com/answerdash.min.js?siteid=756",r.setAttribute("id",s),c.parentNode.insertBefore(r,c)}}(window,document,"script","answerdash-script","AnswerDash");</script> <!-- End of AnswerDash script -->

</html>
